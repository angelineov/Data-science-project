conference,title,description,company
Big Data 2020,Redis: a Multi-Model DB for IoT and Beyond,"An overview of Redis, an open-source multi-model NoSQL DB as a foundation for Big Data projects in the Internet of Things ecosystem and beyond. After a short introduction to Redis, its multi-model capabilities are discussed which make this popular open-source DB a top choice for unstructured data typically found in IoT environments, ranging from simple JSON data to complex graph and timeseries requirements. A few real-world use cases round off this presentation.",Redis Labs
Big Data 2020,Graph Processing for Open Metadata and Governance,Learn how ODPi Egeria uses its distributed virtual graph to connect metadata about an enterprise’s data and IT services from many different tools and then apply governance across this landscape. In this talk we will describe the principles behind the distributed virtual graph and how different technologies can connect in. We will also cover how the JanusGraph technology can be used to fill in the gaps between the tools to ensure the metadata is linked together.,ODPi Egeria & IBM
Big Data 2020,Data Governance From an Engineering Perspective,"For a long time, data governance seemed to me like an empty phrase meaning everything and nothing at the same time. Valdas was on the fence, not sure how to approach it from an engineering perspective.",IT Architect Specializing in Data Analytics and Cloud Computing
Big Data 2020,Introduction to FLaNK Stack,"Introducing the FLaNK stack which combines Apache Flink, Apache NiFi, Apache Kafka and Apache Kudu to build fast applications for IoT, AI, rapid ingest. FLaNK provides a quick set of tools to build applications at any scale for any streaming and IoT use cases.",Cloudera
Big Data 2020,Best Practices for Building Streaming Data Architectures,"The era of big data is over since everybody is a big data company these days. While this sounds super exciting in theory most companies seem to struggle in transforming this characteristic into something that really provides value. To address this problem a new architectural style have been used and it is called streaming data architecture. This architecture style allows companies to harness the power of data by ingesting, storing, and processing data as they happen and at scale to fuel modern analytics based applications.",Elastic
Big Data 2020,Kafka as a Platform: the Ecosystem from the Ground Up,"Kafka has become a key data infrastructure technology, and we all have at least a vague sense that it is a messaging system, but what else is it? How can an overgrown message bus be getting this much buzz? Well, because Kafka is merely the center of a rich streaming data platform that invites detailed exploration. In this talk, we’ll look at the entire streaming platform provided by Apache Kafka and the Confluent community components. Starting with a lonely key-value pair, we’ll build up topics, partitioning, replication, and low-level Producer and Consumer APIs. We’ll group consumers into elastically scalable, fault-tolerant application clusters, then layer on more sophisticated stream processing APIs like Kafka Streams and ksqlDB. We’ll help teams collaborate around data formats with schema management. We’ll integrate with legacy systems without writing custom code. By the time we’re done, the open-source project we thought was Big Data’s answer to message queues will have become an enterprise-grade streaming platform, all in 45 minutes.",Confluent
Big Data 2020,In the Shallow with AI,"As AI technologies continue to integrate and transform our society and organisations, questions around how these augment with human intelligence continues to be of much interest. Many have recognised the need for ‘humans-in-the-loop’ in AI, but most of these efforts have focused on eliciting human interventions at various points in the machine learning process rather than leveraging human ingenuity.In this session we’ll briefly look at:
* The role of objective and subjective data, and how these influence data-driven insights;
* ‘Trans-contextual’ information and the implications for AI; and
* How human ingenuity and adaptability can play an important role in mitigating the unintended and unwanted consequences of AI.",Phoensight
Big Data 2020,5 Pillars of User-Centric Analytics,"How one team created a user-centric analytics program that revolutionized data consumption across the company.
Some consider analytics the dark art of digital transformation. The truth is that, done right, analytics can illuminate the darkest corners of business.Analytics team have seen the power of analytics in action, one that brings the process of creating a truly user-centric analytics program into the light. Today, the team runs an analytics program that aligns with critical areas of decision-making within the company and empowers users with powerful decision-making capabilities every single day.
Join the session to learn more and how to apply the successful analytics strategy to your own organization(s).",ServiceNow
Big Data 2020,"Data Versioning, What Does it Mean?","The demand for better versioning of data is growing. There are a plethora of open source projects providing “data versioning”, “Git for data” and “manage data like code” capabilities (e.g Hudi, DoltHub,, Delta Lake, DVC, Pachyderm, and lakeFS). So how do you know you are choosing the right one? In this talk we will go over the difference between these solutions by clustering them according to 4 main use cases:
1. Collaboration over data: enabling teams to collaborate over data over time, while contributing to the data evolution.
2. Managing ML pipelines: allowing pipeline management of ML projects, from model creation to production.
3. The need for mutability: data formats that grant Insert, Update and delete over an immutable object storage.
4. The need for ACID guarantees over an object storage data lake: using branching logic to manage an object storage based data lake. By the end of the talk, you should have a good understanding of how these solutions compare and which you should choose for different types of use cases. ",Code4Thought
Big Data 2020,"Predicting Cryptocurrency Exchange Rates with Stream Processing, Social Data and Online Learning",Designing a system to cope with loads of billions of events is harder than it seems. In this talk the presenter will go through the most common use cases and pitfalls and provide tips and good practices about how to design systems to avoid them.,Schibsted
Big Data 2020,Azure Synapse Analytics Overview,"Azure Synapse Analytics is Azure SQL Data Warehouse evolved: a limitless analytics service that brings together enterprise data warehousing and Big Data analytics into a single service. It gives you the freedom to query data on your terms, using either serverless on-demand or provisioned resources, at scale. Azure Synapse brings these two worlds together with a unified experience to ingest, prepare, manage, and serve data for immediate business intelligence and machine learning needs. In this presentation, James will talk about the new products and features that make up Azure Synapse Analytics and how it fits in a modern data warehouse, as well as provide demonstrations.",Microsoft
Big Data 2020,Interactive BI Analytics with Presto,"Presto, an open source distributed SQL engine, is widely recognized for its low-latency queries, high concurrency, and native ability to query multiple data sources. Proven at scale in a variety of use cases at Airbnb, Facebook, LinkedIn, Lyft, Netflix, Twitter, and Uber, in the last few years Presto experienced an unprecedented growth in popularity in both on-premises and cloud deployments over Object Stores, HDFS, NoSQL and RDBMS data stores. From the start, Presto was targeting interactive BI analytics involving heterogeneous data sources. Recent improvements like aggregation pushdown, dynamic filtering, data masking and supporting new data sources including Druid, Delta Lake and Elasticsearch, pushed that use case to the next level. During the talk Lukasz and Karol will give a quick introduction to Presto in general, as well as some of its advanced features. They will show a demo, how it works in practice. In addition, they will demonstrate how to integrate different data sources in a data protected environment",Starburstdata
Big Data 2020,Designing and Building Data Science Solutions,The ability to apply data science and AI to business challenges can be impactful and exciting. Yet getting started can be daunting: how best to plan a project in order to ensure success can be unclear. Jon and Neri will share their learnings about sensible approaches to designing data science projects and present a framework that they have found to be useful in giving projects the best chance for success. This talk will largely mirror the material that appears in their book by the same title at https://datasciencedesign.com/.,Spot Intelligence
Big Data 2020,Adding AI Cloud Services to Your On-Prem Data Workflows for NLP & Content Enrichment,"Getting data out of data sources and into your favourite search engine or storage system is often one of the first challenges you face in any data project. There are some ETL tools out there that help you face that issue and consequently there are a lot of data pipelines that are run on-premise: Either based on open source software like Apache NiFi or commercial products. These tools usually offer a variety of transformations but are very limited when it comes to working with unstructured data and enriching that data. However, establishing a process for analysing and enriching unstructured data can be extremely tedious: You need the right persons (e.g. machine learning engineers, data scientists, natural language processing experts), a lot of annotated training and test data, computational power for training machine learning models etc. Cloud services to the rescue! In this presentation Daniel will show how on-premise data processing or indexing pipelines can be extended by cloud services to get more out of your unstructured data while bypassing all the above-mentioned challenges saving time and money.",SHI GmbH
Big Data 2020,From the Earth to the Moon: Lessons from the Space Race to Apply in Machine Learning Projects,"“The space race was a EEUU – Soviet Union competition to conquer the space. This competence helped to develop space technology in an incredible manner, developing other derivative technologies as a side effect.
This race was full of success in both sides, achieving goals that seemed impossible in record time.
From this space race we can learn some lessons that we can apply to our Machine Learning projects to have a bigger success rate in a limited amount of time.”",RavenPack
Big Data 2020,Analyzing Public Data About User Queries on Search Engine to Predict Trends and Evaluate Markets,"Keywords and queries from search engine public data continue to be a beautiful window into people's interests. If we want to use words as an interest analysis tool, however, we need to analyze large volumes of data and manual analysis can be expensive and inaccurate. We Will go through this topic starting from how retrieve data and how to analyze these data with some NLP libraries. ",ByTek
Big Data 2020,"The GDPR Challenges to Big Data, and How to Overcome Them","The GDPR poses real limits on how personal data can be used, but it does not mean the end of data markets, data analysis and data exchange, but the methods to fuel this will radically change. During this talk, Silvan Jongerius, expert in GDPR compliance for technology will explain the obvious and not so obvious challenges of GDPR in big data, and look at different approaches to overcome them. Privacy innovation can help big data businesses to reach their goals without breaking any rules.",TechGDPR
Big Data 2020,Real-Time Streaming with Python ML Inference,"The capabilities of machine learning are now pretty well understood and there are great tools to do data science and construct models that answer nontrivial questions about your data. These tools are often used from Python. The key new challenge is making the trained prediction model usable in real time, while the user is interacting with your software. Getting answers from an ML model takes a lot of CPU/GPU and must be done at serious scale. The ML tools are optimized mainly for batch-processing a lot of data at once, and often the implementations aren’t parallelized. In this talk Marko will show one approach which allows you to write a low-latency, auto-parallelized and distributed stream processing pipeline in Java that seamlessly integrates with a data scientist’s work taken in almost unchanged form from their Python development environment. The talk includes a live demo using the command line and going through some Python and Java code snippets.",Hazelcast
Big Data 2020,ML in Production - Serverless and Painless,"Productionising machine learning pipelines can be a daunting and difficult task for Data Scientists. Fortunately, many novel tools and technologies have become available in the past years to address this issue and make it easier than ever to deploy ML models into production, without the need to configure servers. In this session, Oliver will walk through some of the best serverless options on how to operationalize ML pipelines within the Tensorflow ecosystem and on Google Cloud Platform, based on actual case studies. One of these real-life case studies will dive into the journey of a global cosmetics brand to become packaging-free with the help of ML. The first step towards this goal allows customers to view product information simply by taking a picture. This completely eliminates the need for packaging and labels in stores. However, in order to do this effectively, an accurate image classification model, accessible on mobile phones, is needed. This session will cover the details of the end-to-end machine learning pipeline that was created to deliver and update performance ML models to mobile users.",Datatonic
Big Data 2020,Advanced Analytics in the Industry,"What is the scope in the data use industry? Different views on it are presented in Industry 4.0 Congress; from the description of the power of an artificial intelligence project presented by Gradiant, to real-time decision-making with the experience of Ibermática and its vision of improving OEE based on data. There will be presented also two selected cases from diverse sectors such as the automotive industry (DRAXTON-NAITEC case) or drug design (Phenobyte) that will highlight the importance of having powerful data engineering and enrich the listener’s experience.",GRADIANT
Big Data 2020,Ethical Side of Booming AI,"Nowaday everybody talks about AI and ML as a future for humany. But the thing is that AI, even in it current form will affect human being much deeper then we think. There is a huge ethical gap between what technology can deliver and what we really expect it do deliver. We have to turn our moral compass on. Let’s talk about human-faced side of AI.",Human Technologies
Big Data 2020,Supercharge your Data Analytics with BigQuery ML,"One of the hottest topics in database land these days is BigQuery ML. A new way to use machine learning on top of tabular data straight on your tables without leaving the query editor. With BigQuery ML, you can build machine learning models without leaving the database environment and training it on massive datasets.
In this demo session, we are going to demonstrate common marketing Machine Learning use cases how to build, train, eval and predict, your own scalable machine learning models using SQL language.
The audience will get first hand experience how to write CREATE MODEL sql syntax to build machine learning models such as:
– Multiclass logistic regression for classification
– K-means clustering
– Matrix factorization
– ARIMA time series predictions
– Import TensorFlow models for prediction in BigQuery Models are trained and accessed in BigQuery using SQL — a language data analysts know. This enables business decision making through predictive analytics across the organization without leaving the query editor.",REEA
Big Data 2020,"Real-Time Stream Processing for Insurance & Health Care With Kafka, Kafka Streams and Multi-Runtime Microservices","Insurance companies traditionally heavily used batch processing to manage their data. However, nowadays we expect to have the data ready in near real time. Moreover systems increased in complexity to satisfy new challenging requirements like usage of AI and ML components. As a service provider for insurance companies, pension & healthcare funds we rolled out a resilient stream processing platform running in kubernetes that we can scale out horizontally to integrate different microservices developed in different languages like java, scala or python. To communicate between microservices kafka is used, since it’s scalable and resilient. All microservices are usually stateless and are governed by scala based orchestrators developed with kafka-streams. For python microservices we adopted pykafka, while for scala microservices we heavily uses akka and akka-streams to be able to scale vertically inside a single microservice instance. The state is usually passed along each message down the data processing pipeline, but in case of big payloads (like documents to be classified by ML components) a redis cluster is used for in memory object storage or a mongo cluster if persisted storage is required. In house connectors based on akka are used to operate with traditional relational databases.",PREVINET
Big Data 2020,Introduction to Data Streaming,"While “software is eating the world”, those who are able to best manage the huge mass of data will emerge out on the top. The batch processing model has been faithfully serving us for decades. However, it might have reached the end of its usefulness for all but some very specific use-cases. As the pace of businesses increases, most of the time, decision makers prefer slightly wrong data sooner, than 100% accurate data later. Stream processing – or data streaming – exactly matches this usage: instead of managing the entire bulk of data, manage pieces of them as soon as they become available. In this talk, Nicolas will define the context in which the old batch processing model was born, the reasons that are behind the new stream processing one, how they compare, what are their pros and cons, and a list of existing technologies implementing the latter with their most prominent characteristics. He’ll conclude by describing in detail one possible use-case of data streaming that is not possible with batches: display in (near) real-time all trains in Switzerland and their position on a map. He’ll go through the all the requirements and the design. Finally, using an OpenData endpoint and the Hazelcast platform, he’ll try to impress attendees with a working demo implementation of it.",Hazelcast
Big Data 2020,Making Data Downtime a Pillar of Your Data Strategy,"Barr will introduce the concept of “data downtime” — periods of time when data is partial, erroneous, missing or otherwise inaccurate. Data downtime is highly costly for organizations, yet is often addressed ad hoc. She’ll discuss why data downtime matters to the data industry and tactics best-in-class organizations use to address it — including org structure, culture, and technology.",Monte Carlo
Big Data 2020,Trust and Quality in the Era of Software 2.0,"There is a widespread excitement about the potential of Machine Learning (ML) models, but with market pressures, haste to ship and deliver them; those models fail to deliver what they promise or even worse they can have a negative impact for businesses and individuals. It is our thesis that just as we define quality properties for governing a typical software system from the way it is implemented (e.g. maintainability) to the way it behaves (e.g. functional suitability), we need to do a similar thing for ML models. That is why apart from Accuracy, the so-called F.A.T. properties, (Fairness, Accountability, Transparency) should be essential quality properties for a ML model (or AI system) contributing towards its adoption and trusted governance. In his talk Yiannis Kanellopoulos will present an approach on how an ML model can be evaluated in terms of its Fairness, Accountability and Transparency. Using examples of case studies (from industrial and publicly available datasets) Yiannis will share insights and the benefits one can get by making a ML model accountable, transparent and trying to mitigate its biases.",Code4Thought
Big Data 2020,Towards Enterprise-Grade Data Discovery at ING with Apache Atlas and Amundsen,"From discussing what is AI to practical case studies of AI, Kane will discuss how companies in Hong Kong and world wide uses AI to create business values. Thereafter he will share his experience in working with large multi-international companies. He will discuss potential pitfalls and experiences on what to do and avoid. Finally, Kane will discuss practical tips on how to formulate AI road maps for companies to drive business value.",ThinkCol
Big Data 2020,Machine Learning Engineering,"A successful implementation of the data discovery solution is the key enabler for the true democratisation of data in an enterprise context. It is also a prerequisite for transforming an old-school big data platforms that were primarily designed for ETL processes into robust analytics environment that your data scientist would love.
In the presentation Verdan will share our experience from designing and implementing a data discovery product powered by open-source technologies such as Apache Atlas and Amundsen (initially created by Lyft, and then moved to Linux Foundation). He will discuss the overall architecture, integration with Big Data ecosystem components as well as what kinds of metadata we use to make our solution a powerful and trustworthy solution that facilitates data scientist and analysts work at ING.",ING Bank
Big Data 2020,The Importance of Good Data Quality and Understanding of Visitor Behavior,"In the session, Mats goes through how to measure a person’s journey from being a person in an interesting segment to becoming a customer. He also tells you how to get high data quality on your web visitors so that you can use it in machine learning in Facebook and google. He also addresses what knowledge can be good tools for understanding customer behaviors, such as behavior economics and reverse engineering.",paf
Big Data 2020,Exoplanet Detection Using Machine Learning,"Speaker will introduce a new machine learning based technique to detect exoplanets using the transit method. Machine learning and deep learning techniques have proven to be broadly applicable in various scientific research areas. He aims to exploit some of these methods to improve the conventional algorithm based approach used in astrophysics today to detect exoplanets. Abishek used popular time-series analysis library ‘TSFresh’ to extract features from lightcurves. For each lightcurve, we extracted 789 features. These features capture information about the characteristics of a lightcurve. He used these features later to train a tree-based classifier using a popular machine learning tool ‘lightgbm’. This was tested on simulated data which proved it to be more effective than conventional box least squares fitting (BLS). It produced comparable results to the existing state-of-art models while being much more computationally efficient and without needing more processed versions of lightcurves such as folded and secondary views. On Kepler data, the method is able to predict a planet with an AUC of 0.948 which means that, 94.8\% of the time a planet signal is ranked higher than a non-planet signal and recall of 0.96 meaning, 96\% of real planets are classified as planets. With Nasa’s Transiting Exoplanet Survey Satellite (TESS), a reliable classification system is much needed as we are receiving over a million lightcurves per month. However, classification of this data is harder as lightcurves are shorter. His method is able to classify lightcurves with an accuracy of 98\% and its able to identify planets with a recall of 0.82.",Hawk:AI
Big Data 2020,"Streaming Processing - an Overview of the Concepts, Architecture and Technology of Doing Data Science on Real-Time Data","Streaming Processing (or Fast Data processing) is becoming an increasingly popular subject in financial services, marketing, the internet of things, and healthcare. A typical stream processing solution follows a ‘pipes and filters’ pattern that consists of three main steps: detecting patterns on raw event data (Complex Event Processing), evaluating the outcomes with the aid of business rules and machine learning algorithms, and deciding on the next action. At the core of this architecture is the execution of predictive models that operate on enormous amounts of never-ending data streams. In this talk, Bas will present an architecture for streaming analytics solutions that covers many use cases that follow this pattern: actionable insights, fraud detection, log parsing, traffic analysis, factory data, the IoT, and others. He’ll go through a few architecture challenges that will arise when dealing with streaming data, such as latency issues, event time vs server time, and exactly-once processing. Finally, he’ll discuss some technology options as possible implementations of the architecture.",Aizonic
Big Data 2020,Covid-19: Big Data Analytics and Artificial Intelligence,"With the COVID-19 pandemic spreading across the globe, it’s becoming clear that few can avoid its reach, posing severe challenges to health services and having a range of related social and economic impacts. As governments try to protect lives whilst maintaining economic viability, they are seeking innovative and dynamic solutions to make the right decisions at the right time, particularly in developing countries, which are expected to be disproportionately impacted. This is where insights from mobile data can come into play. This session will focus on the response to COVID-19 data analytics.",Intellisystem Technologies
Big Data 2020,The Intuition Behind the Use of M.L. in Marketing Analytics,"Since 2013, important breakthroughs and advances in technology have made possible to run sophisticated predictive models capable of classifying images, text, sound and are now pervasive in many applications such as self-driving cars, chat bots, translation, among other fields. “Since 2013, important breakthroughs and advances in technology have made possible to run sophisticated predictive models capable of classifying images, text, sound and are now pervasive in many applications such as self-driving cars, chat bots, translation, among other fields. 
Marketing has not been an exception to use these new technologies collectively known as Machine Learning (ML); a sub-field of Artificial Intelligence (AI). This talk presents the key insights that make AI/ML useful for marketing and demystifies the core technology and illustrates case studies where my team applied the technology.
We use AI in creative ways to:- Improve the signal on A|B experiments and have better reads and insights- Advanced segmentation of customers by propensity to act, churn, open an email- Cross sell predictions- Models of resurrection and reactivation- Natural Language to provide insights on content- Loyalty programs. In this talk, Mario will discuss how predictive models are used across these areas
– How to think and interpret predictive models- What metrics we use to evaluate these models- The tools and technologies we use- Specific case studies in optimization, channel attribution", Credit Sesame
Big Data 2020,Stopping Public Transport Coronavirus Infections with Big Data,"The Coronavirus reduced the amount of public transport passengers to a minimum. Passengers fear to be infected by overfilled vehicles. We discuss how Big Data, analytics and forecasting help to limit infections. We give insights of our journey from idea development to the actual situation and share our learnings.",iunera GmbH & Co. KG
Big Data 2020,Orchestrating Data Workflows Using a Fully Serverless Architecture,"Fundbox is a growing fintech company that provides an automatic underwriting platform based on data and AI. While scheduling a limited number of data workflows is a generally manageable task, scaling to hundreds of data workflows with dependencies and diverse job types, requires a substantial customized engineering, complexity, and overall expensive resources. Serverless-based architectures offer an alternative to traditional resource management. Tomer Levi explains how the data engineering team at Fundbox uses AWS StepFunctions, Docker containers, and Spark to build a live serverless data orchestration platform, focusing on their decision to build a user-freindly yet powerful and scalable solution. Tomer will further describe AWS StepFunctions state machines, their limitations, and how to overcome them by building custom job scheduling and dependency features. Finally, the talk will illustrate how resource bottlenecks were overcome using Docker containers and AWS Fargate. Fundbox’s architecture is scalable and already serves dozens of engineers, BI developers and data scientists in the company.",Fundbox
Big Data 2020,Big Data Architecture in the Advertising Industry,"In this session, you will learn how Hybrid Theory’s team of data engineers and data scientists are ingesting billions of events per week to create multiple products using Kafka, Spark and ML. All these multiple components are part of the big data platform supporting the end-to-end process of data exploration, version control of ML models and orchestration of data pipelines via Apache Airflow.",Hybrid Theory
Big Data 2020,From Internet Access Devices Usage to Behavioural Model,"The way of using mouse, keyboard, tablet or phone can be a great source of the information about user behaviour. Data can be gathered from a spectrum of sensors built into these devices. Then this data can be transferred into features which characterize user, like manner of typing, speed of cursor or mouse movement curve. This presentation will focus on how to use those features to build behavioural model which will be unique and adjusted to each of thousends of customers. This problem has some important additional aspects. For one user several different models can be built, therefore some aggregation methods has to be delivered. Some of data has to be anonymized. Continuous authentication is excepted by business. These factors define important limitations for models productionization. They will also be discussed.",Digital Fingerprints
Big Data 2020,Product Management Principles to Drive Businesses in the AI Era,"A significant challenge for companies trying to adopt AI is the gap between the business domain and AI solution domain. On the one hand, the corporate strategists strive for sustainable profitability, but on the other hand, the AI technologists grind over problems like image recognition, prediction or recommendation engines. These are entirely different worlds. How come for some companies, the gap keeps widening, but for other companies, like Amazon and Google, the business excels behind high barriers for market entry? In this presentation, you’ll learn the answers. We will look into how AI product managers offer unprecedented value to navigate their organizations through AI solution adoption and development lifecycle with ease. Adnan will share lessons from decades of work at large corporations, and best practices acquired during consulting for companies in Silicon Valley.","AI Product Institute, Silicon Valley"
