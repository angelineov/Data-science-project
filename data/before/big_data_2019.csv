conference,title,description,company
Big Data 2019,A Practical-ish Introduction to Data Science,"Data Science has been described as the sexiest job of the 21st Century. But what is Data Science? And what has Machine Learning got to do with all of this?
In this talk, Mark will share insights and knowledge that he has gained from building up a Data Science department from scratch. 1. He’ll begin by defining what Data Science is, how it is related to Machine Learning and share some tips for introducing Data Science to your organisation.
2. Next up we’ll run through some commonly used Machine Learning algorithms used by Data Scientists, along with examples for use cases where these algorithms can be applied.
3. The final third of the talk will be a demonstration of how you can quickly get started with Data Science and Machine Learning using Python and the Open Source scikit-learn Library.","Bouvet Norge AS, Norway"
Big Data 2019,You can AI like an Expert,"The talk will discuss Wolfram's progress towards an entirely automated workflow for machine learning that makes it possible for anyone who can code to make use of AI methods.

The talk will assume no knowledge of machine learning and will introduce key concepts before showing how to use the Wolfram Language to create advanced predictors from  Examples will be shown from computer vision such as content recognition, scene recogniton and segmenting images into components relevant for autonomous driving applications. The speaker will attempt to train a predictor using live camera images to be able to recognize the hand gestures of the game Rock, Paper, Scissors.scratch, in seconds. Use will be made of the Wolfram Language functions Predict and Classify which automate the process of data encoding, feature extraction, method selection, training, end decoding. The net result is a single function that produces a ready-to-use classifier or predictor, directly from raw data. Examples will be shown from computer vision such as content recognition, scene recogniton and segmenting images into components relevant for autonomous driving applications. The speaker will attempt to train a predictor using live camera images to be able to recognize the hand gestures of the game Rock, Paper, Scissors. The talk will explain how symbolic computation is the they key ingredient needed to make such automation possible. Symbolic computation provides a unified representation of structured data such as images, sounds, documents, databases, networks as well as the machine learning models themselves. The talk will go on to show that symbolic representation also helps in automating the transition from research experiments to the production deployment of AI services.","Wolfram Research Europe Ltd., UK"
Big Data 2019,Deep Learning for Lazy People... Neural Architecture Search with Automated Machine Learning,"Deep Learning models are great, but choosing the right architecture is not easy. Many times, the easiest way of getting the best architecture is just by trying.
It would be nice to have a clairvoyant that is able to tell us the best architecture, right? We cannot have a clairvoyant but we have tools, like Automated Machine Learning, that are able to find the best architectures just with a few lines of code.This talk will cover the use of Automated Machine Learning (AML) for Deep Learning Architectures, but we will also see other uses of AML.","RavenPack, Spain
"
Big Data 2019,Predicting the Moment of Birth using Sensor Data in Dairy Cows,"Stillbirth, defined as calves that die during unobserved birth is often seen as an indicator of lowered animal welfare in dairy cows. Sensors have been proposed as a tool to support dairy farmers but accurate calving prediction models are often lacking. In this session, a machine learning data pipeline will be described using the spark ML framework. Heavy lifting and feature preparation for sensor data from 1331 cows on 8 herds from 21 days before until the day of calving was performed using sliding windows and time series analysis. In total a set of 100+ features was used in a random forest classification model trained and tested using different cross validation approaches. These different approaches were applied to avoid overfitting to specific cow and herd effects, assuring robust industry applicable models. The data pipeline created a ML model to predict the exact day of calving in dairy cows with an accuracy of 95%, offering a method to diminish unobserved calvings and stillbirth in dairy cows.","Utrecht University, The Netherlands"
Big Data 2019,Knowledge and AI Powering Microsoft & Office 365 Products,"Knowledge, Data and AI have been reshaping the way we live and work for the past few years, and the fact is that this is just the beginning.
Everyone has been using AI-and-knowledge-infused products and services every day, sometimes in ways that may not seem obvious. One of David’s goals in this session will be to explain how these non-obvious scenarios are being powered with Knowledge and AI (and how/why, through improvements in technology, these will just get better).
He wants the audience to understand how intelligent scenarios work by taking them through a journey of understanding Knowledge Graphs (including how knowledge is ingested and/or mined), showing real scenarios being powered by these, and explaining how this technology can/will be used in the enterprise world in products like Office 365 and Microsoft Search. He will explain how the technologies are improving and how this will cause the experiences to improve as well in the next few years.
As part of the session, David will define Artificial Intelligence and will show, with many examples, how this works. He will explain how AI will help people and enterprises and will explain why now is the perfect time for AI. He will show data and numbers which show how big data and AI are (and will become even more) crucial to organizations.
David will explain the difference between Knowledge & AI, and how both are required to power truly intelligent scenarios.
He will talk about key ingredients that will adequately position organizations to be able to power AI/Knowledge scenarios at scale, and he will present Microsoft’s AI Portfolio.
Since Davis currently works on Office 365 and Microsoft Search products, he will also show the latest in these areas.
Finally, for developers in the audience, David will go through Microsoft Cognitive Services that can allow them to infuse AI/Knowledge into their own apps/products.","Microsoft, USA"
Big Data 2019,Practical Data Science - How to Track Your Development Process with DVC,"Datacentric applications utilising machine learning models have evolved into common solutions. Many projects however still suffer from a lack of good patterns and practices, when developing such powerful technologies. Digging down into the nitty-gritty details, we explain how you can use DVC to version all parts of your projects: From the dataset, over gluecode up to the model itself. But wait, there’s more! We show you code that covers the full development cycle, including experiments and reproducability, as well as release and deployment of your model to machines in the wild.","codecentric AG, Germany"
Big Data 2019,(Un)ethical Artificial Intelligence: How to Keep the AI Fair for Everyone,"This presentation highlights the current ethical problems that we face while building artificial intelligence solutions. The artificial intelligence systems based on machine learning algorithms are entering our products at an increasing rate. Unfortunately, keeping these systems fair is hard and a lot of hidden biases enter the models, even if the developers had the best intentions. We will investigate some of the failures of the AI systems and explore ways how to keep them fair for everyone.","Vinted, Lithuania"
Big Data 2019,"Secure IoT Command, Control, and Exfil with Apache MiNiFi","Apache MiNiFi is a lightweight application which can be deployed on hardware orders of magnitude smaller and less powerful than the existing standard data collection platforms. Not only can this data be prioritized and have some initial analysis performed at the edge, it can be encrypted and secured immediately. Local governance and regulatory policies can be applied across geopolitical boundaries to conform with legal requirements. And all of this configuration can be done from central command & control using an existing Apache NiFi instance with the trusted and stable UI data flow managers already love. Recent events (Mirai, Dyn DDOS, etc.) have demonstrated the power of distributed botnets consisting of unsecured IoT devices and reinforced the need to securely command and control IoT devices while also ensuring data is only made accessible to authorized parties.","Cloudera, USA"
Big Data 2019,Big Data Legal Issues. GDPR and Contracts,"In a recent project, iunera sought to determine if it is possible to predict crypto currency exchange rates by utilizing social data from Twitter. Tim will talk about their experiences and describe how they leveraged online learning in conjunction with social data to determine if they are able to predict future currency exchange rates. He’ll point out the general architecture and describe the most interesting findings.
The audience can learn from Tim’s experiences and pitfalls. The new possibilities that open up with more and more Kappa architectures in enterprises leverage new possibilities for real online learning. Therefore, the aspiration is to bring this field in general forward, by sharing insights.","Legal IT Group, Ukraine"
Big Data 2019,"Predicting Cryptocurrency Exchange Rates with Stream Processing, Social Data and Online Learning","In a recent project, iunera sought to determine if it is possible to predict crypto currency exchange rates by utilizing social data from Twitter. Tim will talk about their experiences and describe how they leveraged online learning in conjunction with social data to determine if they are able to predict future currency exchange rates.","iunera GmbH & Co. KG, Germany"
Big Data 2019,Routing Billions of Events a Day: How we Do Routing in Schibsted,"In this talk Carlos will present how his team in Schibsted have set up a streaming data platform using cloud technologies, Kafka and Kafka streams. Schibsted is a leader in media and online classifieds in the Nordic market, delivering news to most of the population of Scandinavia. The streaming platform aims to simplify data management, providing a single point to manage data streams independently of data types. It includes a data quality solution, a data registration solution and a routing solution. Kafka is used as the backbone of the system and the routing solution is built on top of it. Kafka streams is used downstream to enrich streams. The data quality solution allows consumers and providers to register data quality checks and share metrics about the data that is being sent and received. The data registration solution allows providers to register the datasets owned by them, so consumers can find them. At the same time consumers can request access to the datasets and owners can grant access to those datasets, providing visibility and simplifying the sharing process. A key component of the streaming platform is the routing solution implemented using Kafka. This allows consumers of data to request data and adapt it to their own needs by applying filters and transformations, giving great flexibility.","Schibsted, Norway"
Big Data 2019,How can Artificial Intelligence use Big Data for Translating Documents?,"In this session, John will walk us through the exciting world of machine translation. Specifically, he will show us how documents, known as corpora, filled with information from various sources can be used to provide artificial intelligence to a translation system. He will cover the evolution of statistical and neural-based translation systems and how they are currently used to achieve a superior translation quality compared to their predecessors. Big Data, Artificial Intelligence, and Machine Learning architectures will be the highlight of the presentation via a technique called transfer learning. This will be an awesome presentation for those wanting to see how it all fits together!","New York University, USA"
Big Data 2019,From Spark to Elasticsearch and Back - Learning Large Scale Models for Content Recommendation,"Serving tens of billions of personalized recommendations a day under a latency of 30 milliseconds is a challenge. In this talk I'll share our algorithmic architecture, including its Spark-based offline layer, and its Elasticsearch-based serving layer, that enable running complex models under difficult scale constrains and shorten the cycle between research and production.","Outbrain, Israel"
Big Data 2019,Everything you Wanted to Know about Apache Kafka but you Were too Afraid to Ask!Â ,"Streaming platforms have emerged as a popular, new trend, but what exactly is a streaming platform? Part messaging system, part Hadoop made fast, part fast ETL and scalable data integration, with Apache Kafka at the core, streaming platforms offer an entirely new perspective on managing the flow of data. This talk will explain what a streaming platform such as Apache Kafka is and some of the use cases and design patterns around its use. Moreover, this talk will also present and answer a set of random — but recurring — questions from the community about Apache Kafka.","Confluent, USA"
Big Data 2019,Are You Sure about That?! Uncertainty Quantification in AI,"Streaming platforms have emerged as a popular, new trend, but what exactly is a streaming platform? Part messaging system, part Hadoop made fast, part fast ETL and scalable data integration, with Apache Kafka at the core, streaming platforms offer an entirely new perspective on managing the flow of data. This talk will explain what a streaming platform such as Apache Kafka is and some of the use cases and design patterns around its use. Moreover, this talk will also present and answer a set of random — but recurring — questions from the community about Apache Kafka.","inovex GmbH, Germany"
Big Data 2019,Real Time Decision Making in Professionals Sports. From Description to Prediction and Prescription.,"Thanks to the amount of data that has been collected in recent decades in the world of football, we try to answer the right questions that have always existed around it, and from dimensions like never have been answered, such as for example How will a player perform next season in my team, What should I do to avoid conceding a goal? or What should I do so that players are not injured? For this, Artificial Intelligence is the discipline that best adapts to this scenario, being able to aproach the predictive and prescriptive dimensions, beyond the mere description offered by the data collection as currently occurs in the sector and allowing the development of several solutions in the main departments of professional football clubs and related entities.","Olocip, Spain"
Big Data 2019,Big Data Information Architecture for AI,"IBM is famous for Watson, the artificial intelligence system which won the Jeopardy! general knowledge quiz show in 2011. Since then IBM have been feeding it big data and it is being used across industry to help humans work smarter. Here’s a presentation on some of the more interesting case studies from around the world such as Watson Willow at Woodside; the L’Oreal factory and Iplexia demo to show a factory line manager talking to Watson; Olli the self driving cognitive bus you can talk to; Ask Mercedes car manual, and the way we are putting Watson into IBM’s design management application Rational DOORS and IBM’s asset management application Maximo to improve the processes they support using AI.","IBM, UK"
Big Data 2019,Data Discovery with Amundsen,"Company data is increasingly widespread and it has always been difficult to understand who is using which tables or columns, how often and how the dataset was produced. There are commercial tools available that assist for some of these questions, but now there’s also an open-source tool called “Amundsen”, which is already in use by several larger companies. Amundsen helps you answer questions like how a dataset was produced, who else uses it, who’s the owner of a dataset and people using the tool can update the table or column descriptions. Amundsen isn’t around for a very long time, but data lineage and data discovery are already significant problems or at least challenges for companies; Amundsen is a strong answer to these problems, because it doesn’t just focus on the data itself, but also on the people and communities around the data that are using it.","Coolblue B.V., The Netherlands"
Big Data 2019,The Creative Side of AI: Product Name Generation,"Product naming is not an easy task. It requires creativity and a goal-driven process. Can AI help? We propose here a solution to get a very large number in very short time of name candidates to inspire your marketing team from a many-to-many LSTM network. We will explore Recurrent Neural Networks in general and LSTM layers in particular and why they work so well for sequence generation. Kathrin will show how to prepare the data and build, train, and deploy a deep learning neural network in Keras and TensorFlow without writing a single line of code using the open source tool KNIME Analytics Platform.","KNIME, Germany"
Big Data 2019,Computational Propaganda - How Algorithms Influence our Decisions,"“Manipulations in the era of algorithms”. Facebook having 2.2 Monthly Active Users, together with Google and Twitter create three interconnected digital republics where majority of human interactions take place and where increasing amounts of people spend great amount of time daily. Such constellation created fantastic environment for development and usage of targeted ad industry. The same algorithms however have recently gained momentum in being used by bad actors in creation of the so called computational propaganda – custom made messaging aimed at exploiting the micro-vulnerabilities of human mind in order to influence the public discourse and feed people’s decisions. The talk will discuss the casus of Cambridge Analytica, Brexit and the use of bots for influencing people’s decisions.”","Codewise, Poland"
Big Data 2019,Deep Learning at Scale: Distributed Training and Hyperparameter Search for Image Recognition Problems,"Training complex image recognition model on a large dataset using one machine can be long and cumbersome. This talk focuses on methods and libraries, which allow us to train models on a dataset that does not fit into memory, or maybe even on the disk using multiple GPUs or even nodes. The ways of using multiple GPUs and nodes will be discussed and tradeoffs between different approaches will be compared. This talk includes a live demonstration of distributed training of image recognition model on large data set using Horovod and Petastorm on Databricks platform.","Databricks, Germany"
Big Data 2019,Digital Business: Tomorrow is Already Here,"Digital business is about intelligently connecting people, things, and businesses. It’s an infinite world of new possibilities for companies to reimagine their business models, the way they work, and how they compete. New technologies like machine learning, the Internet of everything, blockchain, cloud, and the big data platform will transform value chains to enable completely new ways of doing business and our way of life. Hear how you can deliver a innovative customer experience at scale, with a fully-integrated front- and back-end operations based a solid digital core.","SAP, Germany"
Big Data 2019,Turning a Wasting into a Learning Culture - Combining NLP and Neural Networks to truly Understand and Predict Customers' Behaviour,"Most of the customer feedback of companies around the globe is being wasted, as it is not used to learn, derive insights or to optimize products and processes. At the same time, the amount of customer survey and observation data within companies is growing at heavy speed. The presentation will introduce levers on how to cope with this phenomenon and illustrate, which role Data Science and Machine Learning should Play from an analytical and business perspective. Based on scaled and text feedback of customers, past-oriented data can be turned into predictive causal models that not only explain what truly drives customers loyalty, but also how customer behavior will change in the future based on optimization within the company and its customer service.","LINK Institute, Switzerland"
Big Data 2019,Data Science at PMI - The Tools of The Trade,"Data Science is not a one man show. It is a team effort that requires every team member to master the tools of the trade. This is extremely important for effectively putting data science to work in a global organization. In this talk Michal would like to share with you the best practices to start, develop and ship data science products developed inside PMI the best practices and tools, currently in use by 40+ data scientists across four different location, where data science labs of PMI were established in 2017. He would like to share with you how the technologies (Docker, Artifactory, Jenkins) and methods (templates in Cookiecutter, CI/CD with GitFlow) well-known from software engineering are helping us in creating data science workflow that adapts to specific needs of every peculiar use case we need to deal with, provides transparency at all times, is reproducible not only at the data science but also data engineering and devops dimensions and allows at the same time frictionless development of data products and gives us the freedom to experiment.
Michal would also discuss the “transition challenges” and share some practical hints – for moving from pure exploration in Jupyter to building pip packages that will be put into production as well as for moving from data-to-code to code-to-data approaches in data science challenges. If you’re interested in how Python, Jupyter notebooks, Docker, AWS, Hadoop ecosystem, Spark, Artifactory, Jenkins, Atlassian suite, etc. are setup to support our collaborative work, devoted to building predictive models, this talk is for you.","Philip Morris International, Poland"
Big Data 2019,Optimize your Data Pipeline without Rewriting it,"It is not fast enough! That is one of the more common responses to a data engineer when putting a data pipeline in production. It is easy to dig down into the code and try to optimize it. My experience as a data engineer shows me that it is often easier and more efficient, both in time spent and outcome, to focus on a more holistic view of the pipeline. In this talk, we will look at a structured process to optimize our batch pipelines. We will introduce steps that make our process data-driven instead of a gut feeling. With examples from real-world cases where delivery time was reduced in order by magnitude, we will look on actions where taken.
The intended audience is a beginner to intermediate data engineers. After the talk, you will have a better understanding of how to optimize your pipeline and be able to explain the steps taken for a stakeholder. You will know:
* what metrics to look at
* how to visualize the metrics
* how to detect bottlenecks and other time thieves from the metrics
* what actions to take.","Tink, Sweden"
Big Data 2019,Making Data Scientists Productive in Azure,"Doing data science today is far more difficult that it will be in the next 5-10 years. Sharing, collaborating on data science workflows in painful, pushing models into production is challenging. Let’s explore what Azure provides to ease Data Scientists’ pains. What tools and services can we choose based on a problem definition, skillset or infrastructure requirements?
In this talk, you learn more about Azure Databricks, MLFlow, Azure Machine Learning, Delta Lake, Data Science Virtual Machines and Cognitive Services, with all the perks and limitations.","Cognizant, Lithuania"
Big Data 2019,Real-Time Data Streaming with Azure Stream Analytics,"It’s imperative in today’s world to be able to make split second decisions based on real-time data. Reports based on batch data are great for looking back at trends and potentially making long-term decision, but old data is in many cases already obsolete, and the opportunity to have an actionable impact on the success of a specific process may have been lost. What if we easily could set up a near real-time data pipeline, that could be used to provide complex analytics, and make intelligent actions based on the result? Allow me to introduce Azure Stream Analytics! In this talk, we will take a closer look at the Azure Stream Analytics ecosystem, and look at real world examples streaming twitter feeds as well as sensor data from Raspberry Pi’s, demonstrating how you can build your own burglar alarm.","Excella, USA"
Big Data 2019,Building a Scalable Data Science & Machine Learning cloud using Kubernetes,"Tagline: A real-life story of architecting & building a cloud-native data science platform using Kubernetes. A growing team of data scientists was looking for a simple, flexible, scalable and a secure way of migrating to the cloud as the on-prem data center started becoming a bottleneck. Kubernetes, which enables applications to run on a variety of private and public clouds, along with an ever-growing feature set, matched most of the team’s requirements. In this talk, Murali Paluru, who had the opportunity to work with the Data Scientists team, will share the gathered requirements, architecture and in-depth details of the Data Science platform built on top of Kubernetes. He will also demo a one-click solution that he has developed, to hide away the complexity of Kubernetes and enable the Data Scientists to focus on analyzing the data instead of managing the underlying infrastructure. Data Science is gaining much momentum and is being used by various organizations to get insights into the troves of data being accumulated. The attendees will learn how they can leverage Kubernetes within their teams. They can use the architecture shared in this presentation as-is or build on top of it and they can avoid the common mistakes and pitfalls that would be shared in this presentation.","Rancher Labs, USA"
Big Data 2019,Machine Learning Engineering,"When learning about machine learning methods, much effort is put into the fun part i.e. training and tweaking the models to improve upon your favorite performance metrics. But when the dust settles all these toys need to be working in your production environment and you want to have as little issues with them as possible. In this presentation, we will talk about things that are important if you want your ML system to be healthy and effective, like: testing, monitoring, delayed feedback loops, data quality, etc."," Adform, Poland"
Big Data 2019,The Future of Traditional Shopping Driven by Customer Centric Approaches,"Artificial Intelligence gives retailers a great opportunity to evolve from point of sale to point of experience, convenience and omnichannel. In the coming years e.g., it will be easy to use bots for purchases perceived as boring and monotonous. As a consequence, offline retailers will have to be customer obsessed, keeping them engaged and loyal to their products if they don’t want to fall into an only-transactional buying category. Together with a major European retailer, we leveraged a 6-step Multi-Genre-Analytics approach with the objective of making the current range management customer centric. This required information to determine the wider impact of range changes, understanding e.g. the transferable demand of removed items and shopping missions. The desired outcome was not only to catch affinity effects but also to identify whether customers are loyal to a product or to a brand as removing a loyalty enabling product impacts negatively visits and sales. With the help of deep learning and video analytics, we aim now to be even more efficient optimising range and customer experience. The goal is to give the point of experience the equivalent capability of Web Analytics in the online world. How did this evolve as a business success story?","Teradata Corporation, Germany"
Big Data 2019,A Game Theory Approach for Data Driven Business Decisions: Use Case in Portfolio Optimization,"Companies have a lot of useful information obtained from data that can be transformed into analytical models ready to use in business decision processes.
In this session, we will explore how this information, data and models, can be adapted and enriched in order to include in these company’s decision processes the existence of other players in the market, especially the competitors.
Each player in the market have their own strategies. Are we sure that when we are taking a decision, we are also taking into account all possible strategies of the competitors including retaliate actions? For example, if a company reduces prices, the first expected consequence can be the increase of market share, and then, the increase of the incomes. However, if competitors also reduce prices as a retaliate action the price reduction can be turned into an income reduction (same market share but lower prices). The consequences can be even worse if the initial price reduction starts a price war.
Is It possible to anticipate this outcome in order to avoid it? We propose to study the interaction between different competitors (players) in the market under the game theory scheme. Game theory can be used to answer very relevant business questions like “How can I optimize my portfolio?” or “Can my action start a price war?”. We have built a 3-step process:
First: We build a market simulator based on current customer behaviour, that allow us to simulate any possible portfolio obtaining gains and losses for each player for all possible scenarios.
Second: each player try to optimize the portfolio, modifying it. The portfolio for each player evolves following Monte Carlo simulations under some business conditions.
Third: the portfolio evolution finish when a given convergence criterion is reached, applying game theory equilibrium concepts.
In summary, this model provides Marketing Units with valuable information about possible evolutions of the company portfolio, or even the competitor’s one. Helps Marketing Units understanding the competitive dynamics of the market providing useful insights for the decision processes. So, business units can take initiative when needed, of planning retaliate actions if other players are going to take actions first.","Telefonica S.A., Spain"
Big Data 2019,Predicting Hotel Cancellations with Machine Learning,"Hotel cancellations can cause issues for many businesses in the industry. Not only do cancellations result in lost revenue, but this can also cause difficulty in coordinating bookings and adjusting revenue management practices. This session explores how machine learning techniques can be used to predict hotel cancellations. Firstly, data manipulation techniques with pandas are employed to effectively process over 20,000 customer entries. Feature selection tools such as the Extra Trees Classifier are then used to pinpoint the main drivers of hotel cancellations. The use of logistic regressions, support vector machines, and SARIMA are employed for prediction purposes, and extensive visualisations with pyplot are also generated to illustrate cancellation trends across different time periods.","MGCodesandStats, Ireland"
Big Data 2019,Stream Processing for Analysts with Flink and Nussknacker,"Analyzing and gaining insights from large amounts of data is one thing. Doing it in real time is a whole different business. There quite a few advanced stream processing engines, Apache Flink is one the most widely used. However, designing, testing and deploying streaming jobs usually demand development skills – it’s not so easy for analysts or business people. When Flink was introduced in one the largest Polish telcoms (which is used for real time marketing and fraud detection there), Maciek and his team decided to build open source project – Nussknacker – to make it easier for non-programmers to use all Flink power. Maciek will tell about it and show what they’ve built. The talk will be based on real-world examples – from simple filterings to aggregations and model serving.","TouK, Poland"
Big Data 2019,Overview of Generative Adversarial Networks (GANs),"Until recently, generative modeling of any kind has had limited success. But now that Generative Adversarial Networks (GANs) have recently reached few tremendous milestones (and truly exponential growth in the interest in this technology), we are now closer to a general purpose framework for generating new data. Now GANs can achieve a variety of applications such as synthesizing full-HD synthetic faces, to semi-supervised learning as well as defending and mastering adversarial examples, we can discuss them in this talk. In this talk, we will start with the basics of generative models, but eventually, explore the state of the art in generating full HD images as presented in https://arxiv.org/abs/1710.10196 and dive into adversarial attacks and why this matters to all computer vision algorithms. GANs are a novel approach to generating new data or on a variety of adjacent problems that leverages the power of deep learning and two competing agents to achieve breath-taking results. Now GANs can achieve a variety of applications such as synthesizing full-HD synthetic faces, to semi-supervised learning as well as defending and mastering adversarial examples, we can discuss them in this talk.","Yepic, UK"
Big Data 2019,cGAN for Automatic Site Selection of Cultural Venues [P22404],"While analyzing structured data (even tremendous amounts of it) is a solved mystery nowadays, retrieving actionable insights from unstructured data (i.e. text) is the new challenge to be met. This talk even goes one step further and places this challenge in a streaming data setting. A reference architecture that works across industries will be shown to illustrate how to process text immediately after being written, how to analyze it, how to gather its meaning, and eventually visualize the results to provide actionable insights. This architecture will be composed of several open source projects. When combined, these tools are capable of accomplishing this ambitious task of analyzing streaming unstructured data. The talk will be completed by a live demo that showcases how real-life customer reviews can be processed in real-time to do sentiment analysis on unstructured data and display the results on a dashboard to provide actionable insights.","SHI GmbH, Germany"
Big Data 2019,Big Data Serving: The Last Frontier. Processing and Inference at Scale in Real Time,"The big data world has mature technologies for offline analysis and learning from data, but have lacked options for making data-driven decisions in real time. This talk introduces vespa.ai a mature open source platform for storing, selecting processing and making model inferences over large data sets at end user request time.","VaHa, Belgium"
Big Data 2019,More Than a Query Language: SQL in the 21st Century,"“Great News–The Relational Model is Dead” was a prominent comment on the release of the new SQL standard in 1999. The message behind the provoking statement was that SQL has evolved beyond the relational model. As much as this move was discussed at that time, it took decades until database vendors caught up with this idiomatic change. Many developers haven’t heard of it until today. This talk provides the big picture on the evolution of SQL and introduces some selected modern SQL features by example. You will see that SQL has changed as much as our requirements have changed over the past decades.","winand.at, Austria"
Big Data 2019,Embedded Analytics through Data API or What Big Companies are Hiding from You,"There are more than 20 years of experience of building amazing ETL and BI solutions and tools. These solutions proved being very useful and will serve us in the future.
However, such BI ecosystem was egoistically targeted for closed use cases with a focus on internal needs of companies using it, so only large companies allowed themselves offering great Analytical tools for their customers as self-service. Of course, there are many reasons for that – building such functionality takes enormous development effort, money and time. While the trend of making data more available for end users is there, big tech companies are still not giving access to main building blocks which would allow to easily build Data APIs and self-service embedded analytics to make life easier for many development teams. But the time has changed, and new evolving technologies are moving towards closing the gap and giving opportunities of creating infused Analytics to be used by wide range of companies and users. Let’s discuss coming new approaches, technics and components for better, faster and cheaper development of self-driven Analytics and Data oriented APIs.","Peekdata.io, Lithuania"
Big Data 2019,Best Practices for Building AI Datasets,"Datasets are the most basic building blocks in AI systems, and the most innovative solutions often require manually collecting and labelling data. Yet most teams put their emphasis on magical models instead of solid, high quality datasets. In this talk, I will discuss many of the best practices for building AI datasets from scratch.","Electric Brain Software Corporation, Canada"
Big Data 2019,Runtime Modifications of Distributed Big Data AI Models and Its Parameters,"There has been phenomenal growth of interest in distributed data analysis with large software and other commercial entities. They are trying to construct the solutions that facilitate flexible, scalable and heterogeneous IT-infrastructures dealing with Big Data analysis. Distributed data processing platforms such as Hadoop or Apache Spark became a de-facto standard in the world of Big Data processing, and in cloud economy. The processing pipelines consisting of AI models for such platforms are composed during design time and then submitted to the central (master) component who then distributes the code among several worker nodes. However, in many situations, the application is not static: the users want to add new processing steps, data scientists adjust parameters of their algorithm, testers find new bugs, requirements from user could change, etc. We propose an approach based on AI Planning to make AI models adaptive within distributed processing pipelines by updating them on-the-fly (runtime) in response to changes coming from AI experts, users, the environment, etc.","TNO, The Netherlands"
Big Data 2019,The Journey Through Real Estate Price Model Development,"Together with his team, Vygantas has developed a model that predicts the selling price of homes in Denmark. The development was an exciting journey with many challenges and different attempts to overcome them. Sometimes the build process is more interesting than the final model itself. Thus, Vygantas is very happy to offer you a walkthrough of this experience with all the pains and joys encountered along the way.","Danske Bank, Lithuania"
Big Data 2019,Better Data Exploration and Visualisation with Elasticsearch and Kibana,"Data science has incredibly sophisticated analysis tools which are very effective, but rarely very convenient for their operators. In this live demo we will focus primarily on the prototyping and exploration phase of a data scientist’s workflow. We’ll push a slice of a bigger dataset held in pandas into Elasticsearch. We’ll then use Kibana to build on the fly visualisations and dashboards, allowing us to explore and discover the data’s features in a more intuitive, faster way than writing commands in a jupyter notebook. As Elasticsearch itself is a highly scalable datastore, we’ll discuss how you could take its many abilities beyond prototyping into production if it makes sense for a particular dataset. This demo only includes open source tools or tools free for all use, including commercial.","Elastic, UK"
Big Data 2019,Breakthroughs and the Future of (Deep) Reinforcement Learning,"Due to recent successes in winning computer games against humans, Reinforcement Learning (RL)
received a lot of attention in the media.
This presentation will elaborate the foundation of RL and demonstrate how it is implemented.
Also, it will demonstrate how we can track and understand a system’s learning progress.
Most recent trends of RL research and applications in logistics and pharmacy will be discussed.","Dr. B'hlmeier Consulting, Germany"
