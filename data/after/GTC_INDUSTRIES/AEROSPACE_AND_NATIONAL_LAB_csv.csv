title,description,company,industry
Accelerating Unsupervised SAR Polarimetric Image Segmentation by Parallel Wishart Classifier [P21999],"Our poster presents the unsupervised segmentation of SAR polarimetric images. These images are multi-band areal images of the Earth captured by satellites with special sensors. The process required to segment these images is massive, and the task of segmentation is crucial, as through it we needed to extract important physical information of the area under observation, such as the geometric orientation, structure, shape, and configuration. We propose a much faster parallel implementation of Wishart Classification Based technique that outperforms the vanilla methods by 240%.","Shivam Patel, Visiting Research Student, University of Cambridge",Aerospace / National labs
AI @ The Network Edge (Presented by HPE) [S22480],"It's at the extreme edge of your network, where most data generation occurs. In this session, we'll cover the unique system, software, and data capabilities required to extend AI to the edge in extreme environments. We will also discuss how to extend the data fabric that AI depends on from the edge to other processing elements within the Core and Cloud.","Jeffrey Winterich, DoD Account Chief Technologist, Hewlett Packard Enterprise",Aerospace / National labs
Anomaly Detection on Aircraft Sensor Data Using Deep Learning [s21454],"A vast amount of aircraft sensor data still remains unexploited due to its volume and shear complexity. In 2019, Airbus released, as part of a four-month long challenge, a 65+ gigabyte dataset recorded from real aircraft systems. The goal was to detect a set of anomalies from an unlabeled multidimension time series dataset. We'll describe our solution, which is based on a two-stage approach using auto encoders and long short-term memory neural networks, and how we reached third place out of 160 teams competing. You'll learn the benefits of using autoencoder to achieve dimension reduction in a clustering problem and how LSTM-based neural networks can be applied to detect anomalies in an unsupervised way. We'll dive into the technical details of the solution and discuss the results obtained, as well as potential next steps. Basic knowledge of deep learning-techniques such as Autoencoder or LSTM will help, but isn't required.","Stephane Rion, Deep Learning Scientist, Teradata",Aerospace / National labs
Complex 60 GPU CFD Simulations for Aerospace Gearboxes [s21788],"We'll present a unique new computational fluid dynamics approach to solving the extremely complex multiphase case of an aerospace gearbox model using a purely GPU-based CFD solver, Altair nanoFluidX. The challenge is to better understand the complex flow inside such machinery, as good oil supply to all the key areas inside the gearbox is critical for efficient heat management, lubrication, and fuel consumption. We'll introduce the numerical method used, main challenges of the current state-of-the-art methods, CFD results (flow fields), and performance numbers from the cluster, going all the way up to 60 GPUs.","Milos Stanic, Product Manager, Altair Engineering",Aerospace / National labs
Deep Learning-Based Anti-Drone System [P21900],This poster is about research on detecting and tracking drones by applying deep learning technology to capture drones that are illegally operated.,"Hanseob Lee, Ph.D. Candidate, KAIST",Aerospace / National labs
Deep-Learning Model for Finding New Superconductors [P21328],"We report the first deep-learning model for finding new superconductors. We represented the periodic table in such a way that deep learning can learn it. Although we used only the chemical composition of materials as information, we obtained an R2 value of 0.92 for predicting Tc for materials in a database of superconductors. We obtained three remarkable results. The deep-learning method can predict superconductivity for a material with a precision of 62\%, which shows the usefulness of the model; it found the recently discovered superconductor CaBi2, which is not in the superconductor database; and it found Fe-based high-temperature superconductors (discovered in 2008) from the training data before 2008. These results open the way for the discovery of new high-temperature superconductor families.","Tomohiko Konno, Researcher, National Institute of Information and Communications Technology",Aerospace / National labs
Landing on Mars: Petascale Unstructured-Grid Computational Fluid Dynamics Simulations on Summit [S21584],"We'll present a campaign to investigate the use of supersonic retropropulsion as a means to land payloads large enough to enable human exploration on Mars. The world’s largest supercomputer, Summit, located at Oak Ridge National Laboratory, performs simulations. We'll review the engineering and computational challenges associated with retropropulsion aerodynamics and the need for large-scale resources like Summit. A GPU implementation of NASA Langley Research Center's FUN3D flow solver is used for these simulations. We'll compare the development history, performance, and scalability with those of contemporary HPC architectures. Using an optimized GPU-accelerated computational fluid dynamics solver on Summit has enabled simulations well beyond conventional computing paradigms.","Eric Nielsen, Senior Research Scientist, Nasa Langley Research Center",Aerospace / National labs
Large-Scale Landslides Detection from Satellite Images with Incomplete Labels [P21920],"Earthquakes and tropical cyclones cause suffering for millions of people around the world every year. The resulting landslides exacerbate the effects of these disasters. Landslide detection is, therefore, critical for protecting human life and livelihood in mountainous areas. To tackle this problem, we propose a combination of satellite technology and deep neural networks (DNNs). We evaluate the performance of multiple DNN-based methods for landslide detection on actual satellite images of landslide damage using the capabilities of high-performance GPUs. Our analysis demonstrates the potential for a meaningful social impact on disasters and rescue.","Masanari Kimura, Engineer, Ridge-i inc.",Aerospace / National labs
LUCID: High-Resolution Ground-Based Observations of LEO Satellites with Multi-Frame Blind Deconvolution [s21270],"High-resolution imaging of objects in space from a ground-based observatory is achievable with a sufficiently large aperture, but atmospheric turbulence causes significant degradation. Computationally expensive algorithms can mitigate the blurring effects of turbulence, and these algorithms have only recently begun to leave the domain of CPU-bound computation. We'll describe space domain awareness, the imaging-through-turbulence problem, and algorithms that attempt to solve it. We'll also describe Likelihood-based Uncertainty Constrained Iterative Deconvolution (LUCID), a new multi-frame blind deconvolution implementation that uses CUDA to extract high-resolution images of low-Earth-orbit (LEO) satellites from a series of short-exposure observations.","Michael Werth, Physicist, The Boeing Company",Aerospace / National labs
Super-Resolution of Digital Terrain Data [P21822],"Given a digital elevation model (DEM) at some fixed-grid post spacing, we'd like to better interpolate between the posts to produce a DEM of higher resolution. Intuitively, single-image super-resolution techniques can do that. A neural network is trained on low-resolution elevation data (for example, 90m post spacing) until it can produce a reasonable approximation of higher-resolution elevation data, such as 30m post spacing. Dictionary-based interpolation is achieved through a statistical mapping from low-resolution (LR) features to high-resolution (HR) features, as learned by the hidden layers in the network. This approach shows promising results in producing pseudo-HR elevation models from LR models, and if applied to HR data, can produce pseudo-VHR models suitable for meshing with lidar scans.","Theodore Hromadka, Senior Principal Software Engineer, Centauri",Aerospace / National labs
Using Robust Networks to Inform Lightweight Models in Semi-Supervised Learning for Object Detection [P21789],"Learn from industry practitioners as we present a practical, streamlined data curation workflow designed to mitigate burdens associated with hand-labeled data for supervised learning in object detection. We utilize the capacity of robust object detection networks to efficiently train low-latency networks with access to large pools of unlabeled data but only limited hand-labeled data. By fine-tuning a robust model on the limited examples, we create new, larger training datasets via robust inference on unlabeled data. The combined hand-labeled subset and the inferenced dataset are then used to train a lightweight model. This approach results in more accurate lightweight models with minimal cost from hand-labeled data while also providing an efficient way of curating ground-truth datasets.","Jonathan Worobey, Software Engineer, SURVICE Engineering",Aerospace / National labs
VR Blast Forensics [S21629],We'll present a unique approach of coupling high-fidelity computational physics GPU-based solvers with the software Unity to produce a post-blast forensics virtual reality environment. We'll also cover the benefits of utilizing GPUs to perform both computational physics and VR rendering.,"Phillip Mulligan, Assistant Research Professor, Missouri University of Science and Technology",Aerospace / National labs
WASP: A WeArable SuPercomputing Platform for Lost Person Search-and-Rescue [P22071],"WASP, A WeArable SuPercomputing Platform for Lost Person Search-and-Rescue (SAR), redefines computation at the edge. More than 100,000 people were reported lost in the wilderness and urban settings in the United States in 2017. Use of UAVs for SAR applications shines due to their aerial point of view, enhanced mobility, and wireless connectivity by virtue of unhindered airspace in otherwise-dense foliage. Despite these benefits, the adoption of UAVs in such applications is rendered somewhat infeasible due to their short flight times and limited computation and load-bearing capabilities. WASP, which houses four Jetson Xavier AGXs, aims at offloading computation from the drone to a wearable backpack for the human-in-the-loop searcher, with a high-capacity battery and wireless router. The backpack not only manages massive real-time computational workloads including deep-learning inference, dynamic path planning, and GUI, but also hands-off enhanced control and contextual information to the human searchers.","Chinmaya Patnayak, Student, Virginia Tech",Aerospace / National labs
Accelerating DNN Inference with GraphBLAS and the GPU [S21796],"Our work addresses the 2019 Sparse Deep Neural Network Graph Challenge with an implementation using the GraphBLAS programming model. We'll demonstrate our solution to this challenge with GraphBLAST, a GraphBLAS implementation on the GPU, and compare it to SuiteSparse, a GraphBLAS implementation on the CPU. The GraphBLAST implementation is 1.94x faster than SuiteSparse; the primary opportunity to increase performance on the GPU is a higher-performance sparse-matrix-times-sparse-matrix (SpGEMM) kernel.","Xiaoyun Wang, Ph.D. Candidate, University of California, Davis",Aerospace / National labs
Accelerating Graph Algorithms on Exascale Systems [S21642],"We'll discuss our current efforts for accelerating graph algorithms on the latest US Department of Energy leadership systems. Graph methods are key kernels for large-scale data analytics, as well as for several exascale application domains, including smart grids, computational biology, computational chemistry, and climate science. We'll present our latest results on distributed implementations employing GPUs and accelerators of graph kernels such as community detection and influence maximization, showing how we can tackle large-scale problems with heterogeneous supercomputers.","Mahantesh Halappanavar, Senior Research Scientist and Team Lead, Pacific Northwest National Laboratory",Aerospace / National labs
Accelerating Large-Scale GW Calculations in Material Science [s21353],"Learn the balancing act of porting a large-scale HPC code to modern GPUs, where a plethora of architectural characteristics can both accelerate and limit performance. We'll showcase various techniques used to accelerate the material science code BerkeleyGW on NVIDIA GPUs targeting large-scale simulations with thousands of atoms, matrices of up to 1 million by 1 million, and reductions of thousands of billions of numbers. These techniques include the use of cuBLAS and cuFFT, pinned memory, streams, batched operations, shared memory, and the overlapping of message-passing interface communication and GPU computation. Excellent strong scaling and weak scaling are observed on thousands of Volta GPUs, and a 16x improvement is obtained on FLOPs/Watt efficiency compared to the CPU-only implementation.","Charlene Yang, Application Performance Specialist, NERSC, Lawrence Berkeley National Laboratory",Aerospace / National labs
Accelerating the Singular Value Decomposition: Measuring SVD Performance for Small Matrices [P21776],"Advanced algorithms for spatio-temporal signal processing of data from a phased sensor array often require singular value decompositions (SVD) of a very large number of complex-valued matrices of a relatively small size. Our poster describes a GPU-implemented SVD that we custom-designed for such signal processing applications in order to enable real-time performance. We compare our SVD with tools available in the cuSolver, MKL, and MAGMA libraries, and we document a substantial performance improvement on batches of small square matrices.","Charlotte Kotas, Research Scientist, Oak Ridge National Laboratory",Aerospace / National labs
A Framework for Measuring Hardware Gather-Scatter Support [P21887],"This poster describes a new benchmark tool, Spatter, for assessing memory system architectures in the context of indexed accesses. This type of memory operation is often used to express sparse and irregular data patterns. Gathers and scatters have widespread utility in modern HPC applications, including traditional scientific simulations, data mining and analysis computations, and graph processing. Spatter specifically measures gather / scatter (G/S) variations for multiple platforms, with several tunable backends, including CUDA and OpenMP, and provides comparison metrics for different sparse access patterns. We show how Spatter can be used to evaluate the recent improvements to G/S hardware on NVIDIA GPUs and CPUs, and show performance numbers for STREAM-like, uniform-stride, and application-derived memory access patterns.","Patrick Lavin, Ph.D. Student, Georgia Tech",Aerospace / National labs
A Partitioned Global Address Space Library for Large GPU Clusters [S22093],"We'll discuss NVSHMEM, a PGAS library that implements the OpenSHMEM specification for communication across NVIDIA GPUs connected by different types of interconnects that include PCI-E, NVLink, and Infiniband. NVSHMEM makes it possible to initiate communication from within a CUDA kernel. As a result, CUDA kernel boundaries are not forced on an application due to its communication requirements. Less synchronization on the CPU helps strong scaling efficiency. Ability to initiate fine-grained communication from inside the CUDA kernel helps achieve better overlap of communication with computation. QUDA is a popular GPU-Enabled QCD library used by several popular packages like Chroma and MILC. NVSHMEM enables better strong scaling in QUDA. NVSHMEM not only benefits latency-bound applications like QUDA, but can also help improve performance and reduce complexity of codes like FFT that are bandwidth-bound, and codes like Breadth First Search that have a dynamic communication pattern.","Akhil Langer, Senior Software Engineer, NVIDIA",Aerospace / National labs
A Performance-Portable Diffusion Solver Based on Axom [P21892],"The sheer size and complexity of large-scale multiphysics codes motivate maintenance of a single-source codebase that is parallel and readily portable across different architectures. This is especially attractive due to recent trends toward heterogeneous architectures. We present Mint, an API that provides a mesh-aware, fine-grain, parallel execution model that underpins the development of computational tools and discretization methods. We build a 2D finite-volume diffusion solver that models separation of chemical species that arise in inertial confinement fusion. We demonstrate portability of the solver across two different architectures, one on a CPU-based architecture and one with CPU+GPU architecture. When compiled with the CUDA backend relative to the OpenMP backend, we find up to 3.5x speedup, demonstrating the viability of the API.","Tyler Masthay, Research Assistant, University of Texas at Austin",Aerospace / National labs
Applications of Convolutional Neural Network to the Important Earth Science Problems [P22283],"We applied the convolutional neural network to several Earth science problems that involve (1) discrimination of seismic signals from earthquakes and tectonic tremors; (2) determination of an earthquake hypocenter; and (3) solar radiation estimation from fixed-point camera images. Monitoring tremor activity provides insights into deformation processes of megathrust earthquakes. We could achieve 99.5% accuracy for identifications of signals from tremors, regular earthquakes, and noise. We establish neural networks for the determination of hypocentral parameters. We calculate theoretical seismograms for a realistic 3D Earth model and use these seismograms as learning dataset. We can determine an earthquake hypocenter with this neural network. We develop a new observation method that used deep learning to estimate the amount of solar radiation from images. This new technique can be used to make multifaceted observations.","Daisuke Sugiyama, Engineer, Japan Agency for Marine-Earth Science and Technology",Aerospace / National labs
Big Lasers for Small Accelerators: Exascale Simulations for Better Cancer Therapy [S21850],"Learn how we leverage PIConGPU, an open source, multi-platform particle-in-cell code scaling to the fastest supercomputers in the TOP500 list (Titan, Piz Daint, Summit), to model advanced plasma physics applications. Advances in compact plasma-based accelerators driven by petawatt-class lasers spark great interest in their applications. Ion beams accelerated by intense laser pulses break new ground for treating cancer. Laser-generated electron beams can drive new compact X-ray sources to create snapshots of ultrafast processes in materials and show a path to reaching the energy frontier for studying fundamental physics. We'll present our strategies to harness the power of future exascale supercomputers, handling extreme data flows from thousands of GPUs for analysis with in-situ data analytics and an open data ecosystem. We'll provide detailed performance analysis and show the benefits of PIConGPU for real-world physics cases.","Michael Bussmann, Head of Center for Advanced Systems Understanding, Helmholtz-Zentrum Dresden-Rossendorf",Aerospace / National labs
CUDA C++ in Jupyter: Adding CUDA Runtime Support to Cling [S21588],"Jupyter Notebooks are omnipresent in the modern scientist's and engineer's toolbox just as CUDA C++ is in accelerated computing. We present the first implementation of a CUDA C++ enabled read-eval-print-loop (REPL) that allows to interactively ""script"" the popular CUDA C++ runtime syntax in Notebooks. With our novel implementation, based on CERN's C++ interpreter Cling, the modern CUDA C++ developer can work as interactively and productively as (I)Python developers while keeping all the benefits of the vast C++ computing and library ecosystem coupled with first-class performance.","Axel Huebl, Researcher, Lawrence Berkeley National Laboratory",Aerospace / National labs
Day of the Living Cell: Supercomputers Reveal Molecular Design Principles of Photosynthesis [S21500],"We'll discuss developing the highly parallel molecular dynamics code NAMD for current and upcoming machines, followed by an accessible presentation of results from a decade of work that paves the way to first-principles modeling of whole living cells. One of the many ambitious research projects begun by the late Klaus Schulten was to model, simulate, and ultimately understand the photosynthetic apparatus of bacteria, from the scale of individual atoms to that of the entire cell. The GPU-accelerated supercomputers of Oak Ridge National Laboratory running NAMD have been critical to enabling progress in this continuing work.","James Phillips, Senior Research Programmer, University of Illinois",Aerospace / National labs
Deep Learning for Efficient Modeling of High-Dimensional Spatiotemporal Physics [S22094],"Several research problems in physical sciences are exceptionally complex and high-dimensional, exhibiting spatio-temporal dynamics, non-linearity, and chaos. In an era when vast quantities of such scientific data are generated, building practical, physics-driven reduced-order models (ROM) of such phenomena is crucial. While deep neural networks for spatio-temporal data have shown considerable promise, they face severe computational bottlenecks in learning extremely high-dimensional datasets, often with greater than 10^9 degrees of freedom. These application-agnostic networks may also lack physical constraints and interpretability that is desired in scientific ROMs. We'll present our efforts in leveraging the strong mathematical and physical foundations underlying wavelet theory with the learning capacity of deep neural nets. We'll demonstrate computationally efficient, partially interpretable learning with some embedded physics constraints for modeling large scientific datasets.","Arvind Mohan, Postdoctoral Researcher, Los Alamos National Laboratory",Aerospace / National labs
Dramatic Acceleration of Quantum Transport Simulations: Solving Non-Equilibrium Green’s Function with GPU Devices [P21787],"The poster presents in-depth discussion on technical details and strategies for GPU-driven performance enhancement in solving the Non-Equilibrium Green's Function (NEGF), which is critically used to simulate quantum transport behaviors of electronic devices in a nanoscale regime. Although here we focus on NEGF as a main target of performance enhancement, the contents (particularly the strategies of performance improvement with GPU computing) presented in this poster can be still useful for ANY numerical problems that involve the computation of an inverse of block-tridiagonal (dense/sparse, real/complex) matrices.","Yosang Jeong, Researcher, Korea Institute of Science and Technology Information",Aerospace / National labs
Effective Use of Mixed Precision for HPC [S21725],"We'll discuss how using mixed-precision techniques effectively can significantly speed up current-generation supercomputers, as well as the practical and numerical challenges in adopting such techniques. We'll focus specifically on lattice quantum chromodynamics, which is a regular top-cycle consumer of public supercomputers. Such techniques are an important and sometimes necessary optimization direction for HPC applications.","Kate Clark, Principal Developer Technology Engineer, NVIDIA",Aerospace / National labs
Enabling 800 Projects for GPU-Accelerated Science on Perlmutter at NERSC [S21582],"The National Energy Research Scientific Computing Center (NERSC) is the mission HPC center for the U.S. Department of Energy Office of Science and supports the needs of 800+ projects and 7,000+ scientists with advanced HPC and data capabilities. NERSC’s newest system, Perlmutter, is an upcoming Cray system with heterogeneous nodes including AMD CPUs and NVIDIA Volta-Next GPUs. It will be the first NERSC flagship system with GPUs. Preparing our diverse user base for the new system is a critical part of making the system successful in enabling science at scale. The NERSC Exascale Science Application Program is responsible for preparing the simulation, data, and machine learning workloads to take advantage of the new architecture. We'll outline our strategy to enable our users to take advantage of the new architecture in a performance-portable way and discuss early outcomes. We'll highlight our use of tools and performance models to evaluate application readiness for Perlmutter and how we effectively frame the conversation about GPU optimization with our wide user base. In addition, we'll highlight a number of activities we are undertaking in order to make Perlmutter a more productive system when it arrives through compiler, library, and tool development. We'll also cover outcomes from a series of case studies that demonstrate our strategy to enable users to take advantage of the new architecture. We'll discuss the programming model used to port codes to GPUs, the strategy used to optimize code bottlenecks, and the GPU vs. CPU speedup achieved so far. The codes will include Tomopy (tomographic reconstruction), Exabiome (genomics de novo assembly), and AMReX (Adaptive Mesh Refinement software framework).","Jack Deslippe, Application Performance Group Lead, NERSC",Aerospace / National labs
Enhancing Intra-Node Multi-GPU Stencil Calculations on DGX-2 Using Concurrent-Addressing with Unified Memory [P21784],"In the “CityLBM” project at the Japan Atomic Energy Agency, a real-time AMR (adaptive mesh refinement)-based urban wind prediction code was developed. The next generation of CityLBM code needs ensemble simulations to improve the reliability of the prediction. To achieve that, memory usage should shrink to a single node, or 4-16 GPUs per simulation. To reduce memory usage and accelerate data communication in the AMR code, we tried an intra-node multi-GPU implementation using Unified Memory in CUDA. This approach enables easy parallel-GPU implementation, because the access to Unified Memory is automatically managed from via HBM2 (self GPU) or NVLink (neighbor GPU). We implemented multi-GPU calculations for a 3D diffusion equation and a lattice Boltzmann equation on uniform mesh, and tested weak/strong scalability and NVLink utilization.","Yuta Hasegawa, Scientist, Japan Atomic Energy Agency",Aerospace / National labs
Exploiting Novel GPU Parallelism in the SNAP Interatomic Potential [S21976],"Cutting-edge investigations of material behavior via classical molecular dynamics simulation methods require application-specific, quantum-accurate interatomic potentials (IAPs). The SNAP machine-learning IAP, formulated in terms of general four-body geometric invariants, is trained against quantum electronic structure calculations. This enables the verifiably high-fidelity investigation of diverse material systems at length- and timescales unattainable by purely quantum calculations. Despite the high arithmetic complexity, achieving good SNAP performance with the increasing parallelism provided by modern GPU architectures is challenging. To address this, we have developed a novel parallelization over the geometric structure of the SNAP IAP, prompting memory layout optimizations which facilitate data reuse and reduce memory bandwidth requirements. The new SNAP algorithm will be deployed in the GPU-optimized LAMMPS implementation using the Kokkos templated C++ library.","Evan Weinberg, DevTech Compute, NVIDIA",Aerospace / National labs
Explosive DGX Performance for Weapon Component Modeling [P21870],"At Sandia National Laboratories, we model explosive weapon components using sophisticated simulations. This poster shows how porting those simulations using CUDA and running them on a DGX Workstation provided great speedups, enabling weapon designers a whole new workflow for simulation.","Dan Ibanez, Staff Member, Sandia National Laboratories",Aerospace / National labs
Extensions of TensorFlow-Based Computational Fluid Dynamics [S21816],"The National Energy Technology Laboratory (NETL) recently developed a completely TensorFlow-based computational fluid dynamics code for single-phase flow as a potential next-generation solver for Multiphase Flow with Interphase eXchanges (MFIX). NETL demonstrated over a 3x speedup using NVIDIA V100 GPUs on a DGX-1 before any domain decomposition was implemented. NETL is currently working on implementing parallel linear solvers in TensorFlow. In addition, NETL has strategically chosen to invest in a TensorFlow-based Multiphase Particle-In-Cell (MP-PIC) methodology. We'll cover the most recent developments to further the TensorFlow-based solver, and discuss plans for AI/ML acceleration.","Dirk Van Essendelft, General Engineer, The National Energy Technology Laboratory",Aerospace / National labs
Fromage Optimizer for Deep Neural Networks [P22300],"We propose a new geometric characterization of neural network loss surfaces, called deep relative trust. This characterization suggests a new optimization algorithm that we call Fromage, short for ""Frobenius matched gradient descent."" Experiments with the optimizer on standard deep learning benchmarks—including Transformer and GAN—are promising.","Jeremy Bernstein, Ph.D. Student, California Institute of Technology",Aerospace / National labs
"GPU-Accelerated Deep Learning for Weather, Climate, and Space [s21255]","We'll demonstrate how to use deep learning to tackle important challenges in weather forecasting, climate modeling, and the processing of satellite observations. We'll present recent results from ongoing research collaborations with the National Oceanic and Atmospheric Administration, NASA, and various universities, and explain how accurate results were achieved. We'll show how to automate feature detection to identify threats from severe weather, solar storms, and near-earth objects, and we'll discuss how to accelerate weather/climate models and data assimilation techniques to produce more accurate predictions. Finally, we'll illustrate how to better use satellite observations by enhancing, transforming, interpolating, fusing, and repairing multispectral data.","David Hall, Senior Solution Architect, NVIDIA",Aerospace / National labs
GraphDefense: Toward Robust Large-Scale Graph Convolutional Network [P21806],"We study the robustness of graph convolutional networks (GCNs). Despite the good performance of GCNs on graph semi-supervised learning tasks, previous works have shown that the original GCNs are very unstable to adversarial perturbations. Inspired by the previous works on adversarial defense for deep neural networks, and especially adversarial training algorithm, we propose a method called GraphDefense to defend against the adversarial perturbations. In addition, for our defense method, we could still maintain semi-supervised learning settings without a large label rate. We also show that adversarial training in features is equivalent to adversarial training for edges with a small perturbation. Our experiments show that the proposed defense methods successfully increase the robustness of Graph Convolutional Networks. Furthermore, we show that with careful design, our proposed algorithm can scale to large graphs, such as Reddit dataset.","Xiaoyun Wang, Ph.D. Candidate, University of California, Davis",Aerospace / National labs
Hedgehog: A Performance-Oriented General Purpose Library that Exploits Multi-GPU Systems [s21227],"We'll present Hedgehog, a general-purpose library for taking advantage of powerful compute nodes, multicore CPUs, and multiple GPUs. The novel aspects of Hedgehog are: (1) its explicit representation of a program as a dataflow graph, (2) its pure dataflow-driven scheduling, (3) its maintenance of a computation’s localized state via state managers, and (4) its fine control of memory via memory managers. This dataflow approach results in extremely low overhead for task executions (< 1 microsecond) and no-cost profiling at the task level. This allows us to prototype operations that compare favorably with leading libraries such as cuBLAS-XT.","Tim Blattner, Computer Scientist, NIST",Aerospace / National labs
"High-Throughput 3D Image Reconstruction, Visualization, and Segmentation of Large-Scale Data at the Sirius Synchrotron Light Source [s21278]","We'll present highly efficient tools for large-scale 3D image reconstruction, visualization, and segmentation being developed for the Sirius synchrotron light source. Sirius will be the second fourth-generation synchrotron in the world, and will acquire 3D/4D images with resolution up to <50 nm using hard X-rays. With NVIDIA, we're creating integrated pipelines to reconstruct 3D images from modalities such as coherent-diffraction imaging and transmission tomography, visualize the data in streaming mode, and segment the images to provide almost real-time feedback. We rely on multi-GPU/node CUDA programming and machine/deep learning-optimized inference to address the issues, given that each 3D image may be larger than 100 GB and may be acquired down to 1s, resulting in around 50 TB of data of a wide variety of samples (for example, biological and geological) expected to be produced every day.","Thiago Vallin Spina, Researcher, Brazilian Synchrotron Light Laboratory / CNPEM",Aerospace / National labs
High-Throughput Real-time Data Processing with GPUs at CERN [s21341],"We'll present the design and performance considerations and system optimization of a GPU-based, real-time physics selection system at a Large Hadron Collider experiment. Millions of particles collide every second at the LHCb experiment at CERN in Switzerland. To select interesting particle collisions, data must pass through an acquisition system and be filtered with real-time selection software. The throughput processed in the first stage of this streaming data processing application amounts to 40 terabytes per second, and the efficiency of the selection is crucial toward improving our fundamental understanding of the universe. In order to process this massive data throughput in real-time, we developed GPU physics reconstruction software called Allen. The Allen framework hands the raw data to GPU streams, which perform the decoding, reconstruction, and selection of particle collisions.","Daniel Hugo Cámpora Pérez, Research Postdoc, NIKHEF and University of Maastricht",Aerospace / National labs
HPL-AI: Benchmarking Half-Precision Hardware with Modern Numerical Linear Algebra [S21470],"We'll present the mixed-precision iterative and direct methods used by the HPL-AI benchmark. These new approaches are instrumental in kernel-based performance evaluation of modern hardware accelerators that offer fast implementation of limited-precision floating-point units. The scope of the benchmark spans a number of important computational patterns that scientific codes, both in the past and on modern GPUs, often rely upon. We had to resolve a number of numerical issues to achieve a robust implementation, and we'll present those results for relevant background on the design process involved in benchmarking and how it can be leveraged for the benefit of the GTC audience.","Piotr Luszczek, Research Assistant Professor, University of Tennessee",Aerospace / National labs
Improving Geophysical Turbulence Models with Machine Learning [S21574],"In large-scale geophysical flows, the relatively small-scale processes of turbulence and mixing can have a leading-order impact on the prediction of (for instance) ocean circulation and global energy budgets. Such predictions are critical components of weather and climate simulation — geophysical problems where small-scale models help offset the otherwise prohibitively expensive computational cost of simulation. These turbulence closure models attempt to capture dynamics that have complex functional dependence on a potentially broad range of large-scale flow parameters. However, models and frameworks are often phenomenological and heuristic in nature, such that robust model calibration to simulation, observation, and experiment data is a challenge. We'll explain how a nonintrusive supervised GPU-driven machine learning framework, such as Neural ODE, can help improve the state of turbulence models in canonical geophysical flows. We'll also discuss the interpretability of these machine-learning models and provide a roadmap to create more general frameworks for modeling such physics.","Peetak Mitra, Computational Physics Intern, Los Alamos National Laboratory",Aerospace / National labs
Improving Ocean Model Framework NEMO with GPU Port and Asynchronous Execution [P21955],"Our work describes the improvement of an operational ocean model framework (NEMO) with routine porting and asynchronous execution in large-scale clusters using CUDA. We show routine GPU optimizations speed-up and implementation of asynchronous execution over large scale workloads. Considering that NEMO is a standard production framework for research activities and forecasting service, we aim to expose the ongoing challenges of accelerating Fortran/MPI long-term applications aligned with the needs of a broad community of developers.","Maicon Faria, HPC Support Specialist, Barcelona Supercomputing Center",Aerospace / National labs
"Integrating NVIDIA Tesla V100 GPUs into a Cray System for a Diverse Simulation, Machine Learning, and Data Workload [S21569]","The HPC system ""Perlmutter"" will the first GPU-accelerated production system at the U.S. Department of Energy’s National Energy Research Scientific Computing Center (NERSC) when it is deployed in 2021. We'll explain how, to enable its users to prepare their applications for Perlmutter, NERSC recently integrated 18 GPU-accelerated compute nodes into its current production system, the Knights Landing-based Cray system ""Cori."" These nodes’ primary purpose is application development and profiling for GPU acceleration, as part of the NERSC Exascale Science Application Program (NESAP). Despite significant differences in hardware from the rest of the Cori system, the GPU nodes have been configured such that, from both the user’s and the administrator’s perspective, they are seamlessly integrated into Cori. This integration has streamlined access for hundreds of NESAP users to these nodes, and facilitates a diverse workload of NESAP applications spanning simulation, data-intensive workloads, and machine learning.","Brian Friesen, Application Performance Specialist, Lawrence Berkeley National Laboratory",Aerospace / National labs
Interpretable Deep Learning for Hurricane Intensity Prediction [S21548],"Hurricanes can experience rapid increases in intensity, in which they can strengthen from a tropical storm to a major hurricane in only a couple of days. These rapid intensification periods are currently difficult to predict, but deep learning may be able to detect spatial patterns in the storms that are precursors to rapid intensification. We'll show how a convolutional neural network trained on output from the Hurricane Weather Research and Forecasting model can produce probabilistic estimates of rapid intensification. We'll also show how deep-learning interpretation techniques can reveal what storm structures are associated with rapid intensification versus rapid weakening.","Richard Loft, Director of Technology Development, Computational and Information Systems Laboratory, National Center for Atmospheric Research",Aerospace / National labs
Learning the Hard Parts: Scaling Reacting Flow Simulations with Machine Learning [S21740],"Explore a new technique for overcoming bottlenecks in computational fluid dynamics with machine learning. We'll describe using a neural chemistry solver for an order-of-magnitude speedup, opening the doors to problems that are currently impossible. Simulating chemically reacting flow — fluid flow with a chemical source term (such as a flame) — is computationally prohibitive: an at-scale combustor simulation with a practical hydrocarbon fuel can take years! Solving the chemical source term dominates this process, taking up to 90% of the total compute time. This share increases for more complex reactions, resulting in poor scalability. We'll discuss designing a neural network to model hydrogen combustion; integrating this neural chemistry solver into computational fluid dynamics code; analyzing the performance of this new approach; and discussing how these lessons could be applied to other CFD bottlenecks.","Adam Moses, Computer Scientist, Naval Research Lab",Aerospace / National labs
Matrix-Free Real-time Online Reconstruction of Compressive Focal Plane Array Camera [P21865],"This study proposes a solution for online and real-time reconstruction of compressive focal plane array cameras. These cameras enable high-resolution imaging using low-resolution sensors through compressive sensing reconstruction. Here, we use a spatial light modulator for encoding high-resolution data onto low-resolution sensors. Then, we solve an optimization problem for reconstruction. Previous methods involve reconstruction through algorithms that require many batched matrix multiplications. In this study, we propose using an algorithm that does not involve any matrix multiplication and show its performance against the previous method. Due to the high computational load of the image reconstruction algorithms, we use GPUs for fast computation. Moreover, we show that the camera can work in real time by sampling each data online and reconstruction frames in real time in a pipelined fashion. Finally, we show the reconstructed images through OpenGL interoperability library.","Alper Gungor, Senior Research Engineer, Aselsan Research Center",Aerospace / National labs
Optimizing Stencil Operations in OpenACC [P21723],"Stencil operations are used widely in HPC applications and pose an optimization challenge on both CPUs and GPUs. On GPUs, fine-tuned optimizations can be formulated using low-level APIs such as CUDA, but many large established codes prefer a portable, higher-level API such as OpenACC. Although OpenACC lacks the fine-tuning of CUDA, it does allow for some tuning through a variety of parallelization constructs and loop directives. Here, we optimize a stencil operation within our production solar physics research code Magnetohydrodynamics Around a Sphere. We explore numerous OpenACC directive options (including tile, cache, collapse, etc.) and compare their performance over several problem types and sizes. The optimal result is used to run a full-scale simulation and analyzed with Nsight Systems. An emerging cautionary result is that although many directive options yield a speedup of the operator, using the ""wrong"" directives can result in drastically poor performance.","Ronald Caplan, Computational Scientist, Predictive Science Inc.",Aerospace / National labs
"Performance Comparison of Search for Neighbor-Particle in MPS on Xeon, Xeon Phi and GPU [P21969]","The MPS method is a particle-based simulation used for computation fluid dynamics. It was originally developed for simulating fluid dynamics such as fragmentation of incompressible fluid. Target fluid or objects are divided into particles and each particle interacts with neighbor-particles. Searching for neighbor-particles is the main bottleneck of MPS. We’re researching and developing the in-house program called P-Flow_lite. We're proposing two optimizations for a search for neighbor-particles and implementing them on Xeon, Xeon Phi, and GPU by using directives. V100 is the fastest among them.","Takaaki Miyajima, Postdocoral Researcher, RIKEN Center for Computational Science",Aerospace / National labs
Roofline Performance Model for HPC and Deep-Learning Applications [s21565],"Learn how to use the Roofline model to analyze the performance of GPU-accelerated applications. We'll cover the basics of the model, explain how to use tools such as nvprof and Nsight Systems/Compute to automate the data collection, and demonstrate how to track progress using Roofline for both HPC and deep-learning applications. We'll use examples such as GPP from material science, high-performance geometric multigrid from adaptive mesh refinement, and two kernels from TensorFlow to show how characteristics such as arithmetic intensity, memory access pattern, and thread divergence/prediction can all be captured by Roofline, offering useful insights to performance optimization.","Charlene Yang, Application Performance Specialist, NERSC, Lawrence Berkeley National Laboratory",Aerospace / National labs
Scalable Workflow System for Whole Slide Microscopy Analyses Using Neural Networks [P21983],"We present a streaming, asynchronous, high-throughput workflow for joining traditional computer vision and artificial intelligence inference across multiple models using the Hybrid Task Graph Scheduler and TensorRT for scalable, single-node, multi-GPU object detection, classification, and regression. Our approach targets very large (100k x 50k pixel) automated whole-slide microscopy imaging, which operates under tight time constraints. The end-to-end workflow starts with a microscope scan and finishes with a populated database containing quality-assurance metrics, object detections, and other salient features. This generalizable workflow applies three independent TensorRT models, with dependency management, concurrently across all available GPUs within a single computer.","Tim Blattner, Computer Scientist, NIST",Aerospace / National labs
Scaling Data by 109x and Compute for Deep-Learning Applications [S21390],"We'll explore the scalable applications of artificial intelligence on massive data sets. First, we'll cover how we optimized and developed highly parallelized implementations of DL algorithms and tested them on HPC GPU clusters. Then we'll demonstrate how to develop models that can run over large high-resolution datasets, identifying the spatial and temporal relationships between physical parameters in global-scale high-resolution numerical weather prediction models.","John Taylor, Program Leader, DST/CSIRO",Aerospace / National labs
The Rocky Road to Tasking: Task Queues Reloaded [S21189],"We'll show you how to parallelize your irregular algorithm on GPUs with tasking, starting with an overview of our CUDA C++ tasking framework for fine-grained task parallelism. After touching on persistent threads, synchronization mechanisms, and load balancing, we'll present diverse optimization strategies. First, we'll describe the implementation of task queues based on static memory allocation. Second, we'll show how to implement work sharing on a GPU through hierarchical task queues. Third, we'll present a thread coordination scheme to reduce contention on the task queues, thus keeping all threads busy. We'll analyze each optimization step's performance gains for a prototypic implementation of a task-based fast multipole method for molecular dynamics.","Ivo Kabadshow, Scientist, Jülich Supercomputing Centre",Aerospace / National labs
"Tiny, Tiny Tasks: Fine-Grained FMM Tasking on GPUs [P22059]","Learn how fine-grained task parallelism occurring in many HPC applications can be exploited with GPUs. In contrast to available tasking approaches (e.g. CUDA graphs) that rely in some part on the involvement of the host CPU by scheduling new tasks, we present a scheme to fully control the execution of tasks by the GPU without additional synchronization or data movement from the CPU. A fine-grained formulation of tasks can lead to more available parallelism at any given time, and may thereby help to reduce the runtime even further. The poster will show the current concept of our GPU-tasking for the Fast Multipole Method. However, our ideas can be reused for other, especially hierarchical, algorithms. We'll discuss common bottlenecks and pitfalls when applying fine-grained tasking on a GPU.","Laura Morgenstern, Ph.D. Student, Computer Science, Jülich Supercomputing Centre",Aerospace / National labs
Toward an Exascale Earth System Model with Machine Learning Components: An Update [S21834],"Many have speculated that combining exascale GPU computational power with machine-learning algorithms could radically improve weather and climate modeling. We'll discuss the status of an ambitious project at the U.S. National Center for Atmospheric Research that's moving in that direction. Having achieved performance portability for a standalone version of the Model for Prediction Across Scales-Atmosphere (MPAS-A) on heterogeneous CPU/GPU architectures across thousands of GPUs using OpenACC, our project has begun looking at two new directions. First, we've launched an effort to port the MOM-6 Ocean Model. Second, machine-learning scientists at NCAR and elsewhere have begun evaluating replacing atmospheric parameterizations with machine-learned emulators, including the atmospheric surface layer, cloud microphysics, and aerosol parameterizations. We'll also discuss related efforts to apply machine-learning emulation to model physics.","Richard Loft, Director of Technology Development, Computational and Information Systems Laboratory, National Center for Atmospheric Research",Aerospace / National labs
Turbulence Forecasting via Neural ODEs [P22054],"Fluid turbulence is characterized by strong coupling across a broad range of scales. Furthermore, besides the usual local cascades, such coupling may extend to interactions that are non-local in scale-space. As such, the computational demands associated with explicitly resolving the full set of scales and their interactions, as in the direct numerical simulation of the Navier-Stokes equations, are so high in most problems of practical interest that modeling of scales and interactions must be reduced before further progress can be made. While popular reduced models are typically based on phenomenological modeling of relevant turbulent processes, recent advances in machine-learning techniques have energized efforts to further improve the accuracy of such reduced models. In contrast to such efforts that seek to improve an existing turbulence model, we propose a machine learning methodology that captures, de novo, underlying turbulence phenomenology without a pre-specified model form.","Peetak Mitra, Computational Physics Intern, Los Alamos National Laboratory",Aerospace / National labs
Workload Management for Complex Workflows on a GPU-Enabled Heterogeneous System [s21608],"The National Energy Research Scientific Computing Center, the U.S. Department of Energy mission supercomputing center, is integrating experimental science workflows into its existing HPC-centric workload. This introduces new scheduling requirements, including real-time computing demands and complex workflows that depend on external services, data, and devices. These new workflows also need to co-schedule heterogeneous job components, with detailed subtask scheduling on both GPUs and CPUs. It is challenging to maintain scheduler responsiveness to this dynamically changing workload on an extreme-scale HPC system. We'll explain innovations that NERSC introduced to the Slurm scheduler to help meet these challenges, enhancing the scheduling algorithm to enable full-scale jobs and single-core jobs to schedule fairly, and adapting reservation and preemption capabilities to allow real-time computing. We'll also show enhancements to support Linux containers both for user software and system resources, as well as heterogeneous job execution.","Douglas Jacobsen, Group Lead, Computational Systems Group, Lawrence Berkeley National Laboratory",Aerospace / National labs
