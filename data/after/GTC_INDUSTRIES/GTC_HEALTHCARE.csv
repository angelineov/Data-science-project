title,description,company,industry
3D Analysis Data Generation from X-ray Data for HealthTech by DGXs [P22304],"In Japan, research on regenerative medicine is advancing, various levels of treatment are advancing, and laboratories dealing with nearly 1,000 regenerative medicine cells are starting to appear every week. Research in these regenerative treatments requires new medical imaging—to increase the resolution of two-dimensional image data, for example. Rather than discovering new indicators that map annotations, it is easier to use existing indicators or to generate images for use. Currently, a 3D image is generated from a 2D image by X-ray, and a 3D curved surface learned by a Tesla chip is developed to generate a realistic 3D image. By generating even sliced images, we provide digital data materials that can be used as reference for proceeding to MRI after X-ray imaging.","Shigehisa Omatsu, CEO, Stellaplace, Inc.",Healthcare & Life Sciences
Accelerate Quantitative Clinical Neuroimaging Analysis with AI: Steps Toward Personalized Disease Progression Monitoring in Clinical Neurology [S21421],"Quantitative neuroimaging analysis can further extract critical information from diagnostic imaging. For instance, brain-volume change has been considered as a critical biomarker in neurodegenerative disease progression. Instead of describing the brain shrinking process as ""moderate"" or ""severe"" through visual inspection, now we can, with computing, precisely measure the brain-tissue loss at the scale of 0.1% with conventional MRI scans. However, precision and accuracy of the analysis often require an expert level of quality control, usually carried out by certified imaging analysts at dedicated imaging reading centers. Deep learning and GPU acceleration make it possible to transfer complex and sophisticated analysis into fully automated assessment in daily clinics. We'll share views from both imaging scientists and clinicians on how AI is accelerating clinical imaging quantitative biomarker research.","Tim Wang, Director of Operations, Sydney Neuroimaging Analysis Centre",Healthcare & Life Sciences
"Accelerating Cancer Research: VDI by Day, Compute by Night [S21845]","The Netherlands Cancer Institute–Antoni van Leeuwenhoek Hospital (NKI-AVL) is one of the top 10 comprehensive cancer centers in the world. By combining cancer care, research, and by exchanging knowledge internationally, they make a significant contribution to solving the cancer problem in the 21st century. To meet that challenge, NKI-AVL built a software-defined infrastructure to accelerate research and enhance efficiency for clinicians. During daytime, the VDI infrastructure will give health care professionals fast, remote, and secure access to patient data. At night, the same VDI platform is utilized by researchers to execute computational GPU workloads. As a result, the high-performance and flexible IT infrastructure enables physicians and nurses to spend more focused time on patient care, and researchers to advance new discoveries in cancer treatment.","Roel Sijstermans, IT Manager, Antoni van Leeuwenhoek Hospital and Netherlands Cancer Institute",Healthcare & Life Sciences
Accelerating Quantum Chemistry Simulations with AI [S21273],"We'll discuss computational chemistry applications of machine learning covering three topics. First, we'll examine the use of neural networks and other machined-learned methods for describing a quantum-accurate potential energy surface. Second, we'll cover graph convolution neural networks and graph message-passing networks for predicting molecular properties at a fraction of the cost of traditional electronic structure calculations. Third, we'll discuss variational autoencoders for molecule discovery and illustrate their application to drug discovery.","Abe Stern, Senior Data Scientist, NVIDIA",Healthcare & Life Sciences
Acceleration of Wavefront Analysis Using Zernike Polynomial Fitting [P21849],"Zernike polynomial fitting can analyze the wavefront map of biological cells with uniform contents. Aberrations not only indicate changes in the wavefront after passing through cells, but also provide angular position for tomogram reconstruction. However, Zernike polynomial fitting for wavefront analysis is time-consuming. To raise efficiency, we implemented Zernike polynomial fitting on a GPU card. We simulate a sequence of red blood cell phase maps with various rotation angles, and estimate the angles using the coefficients of defocus, vertical, and horizontal tilts from Zernike analysis. The error of angle estimation is under 0.7%, and we achieve video-rate processing at 128×128 pixels. This shows the possibility for implementing wavefront analysis on a GPU card and its benefit on tomogram reconstruction.","Yang-Hsien Lin, Ph.D. Candidate, National Taiwan University",Healthcare & Life Sciences
Accurate Multiple Sclerosis Lesion Segmentation Using Deep Learning [P21889],"We present results of a comparison of multiple deep neural networks (DNNs) performing image segmentation for multiple sclerosis (MS) brain lesions. MS is an autoimmune disease that leads to demyelinating lesions in the central nervous system. Measuring disease progression via brain magnetic resonance imaging (MRI) is an important part of managing MS. Manual segmentation of MRI brain lesions by radiologists is time-consuming and subject to high user variability. Our poster shows the results of using three different DNN architectures, trained using NVIDIA GPU. You'll learn about using neural network for medical image segmentation, particularly applied to the measurement of MS brain lesions. You'll also learn about different DNN architectures, including Inception-based convolutional networks and U-Net based networks, as well as techniques used to compare automated segmentation results to each other and to human expert segmentation.","Ethan Ocasio, Chief Technology Officer, Girls Computing League",Healthcare & Life Sciences
"AI Methods to Transfer Natural Language into Actionable Knowledge in Medicine: From Radiology, Pathology Reports to Social Media Posts [S22150]","Learn about the key types of use cases for AI-driven natural language processing (NLP) that will ultimately improve medical and public health practice by mining humongous amounts of free text from clinical notes and social media posts. First, we'll describe methods to leverage narrative reports associated with radiological scans to automatically generate labels for creating large annotated image datasets, and we'll highlight its application to different domains of radiology (CT, MR, US). Second, we'll discuss the challenge of clinical prediction and present innovative longitudinal XAI approaches (AI with explainability) to improve clinician acceptance. Finally, we'll discuss the emerging use of publicly available social media data in medicine and public health. While it is challenging to execute data mining from this resource, we'll present successful NLP pipelines that can convert this noisy language data into valuable and actionable knowledge.","Imon Banerjee, Assistant Professor, Emory University",Healthcare & Life Sciences
A New Era of Medical Imaging [S22554],"Deep Learning has revolutionized medical imaging research and has become an essential element for every single step of the imaging pipeline. In this session, we will discuss some recent trends and share key learnings from related conferences. We will go through the general imaging pipeline - from signal, to image, to image understanding, to actionable insights - and provide examples how Deep Learning can accelerate, augment and improve various steps of the pipeline. And even enable the previously impossible.","Nicola Rieke, Senior Deep Learning Solution Architect - Healthcare, NVIDIA",Healthcare & Life Sciences
"Animation, Segmentation, and Statistical Modeling of Biological Cells Using Microscopy Imaging and GPU Compute [s21944]","This presentation describes the use of GPU compute in the Allen Institute for Cell Science. The mission of the Allen Institute for Cell Science is to create dynamic and multi-scale visual models of cell organization, dynamics, and activities that capture experimental observation, theory, and prediction to understand and predict cellular behavior in its normal, regenerative, and pathological contexts. Our first project is to understand how the parts of the cells integrate to determine diverse cellular behaviors as revealed through 3D live-cell imaging, creating a dynamic and animated virtual model of the cell. We will describe three applications where we use GPU-compute solutions for our research; these include (1) animation, (2) segmentation, and (3) statistical modeling of biological cell images.","Theo Knijnenburg, Director Machine Learning and Computational Biology, Allen Institute for Cell Science",Healthcare & Life Sciences
Building a Medical Imaging AI Ecosystem Using Clara SDKs [s22295],"This product talk will give an overview of Clara Imaging Application Framework and will focus on the latest feature updates for accelerating data annotation, domain-optimized training, Iterative & high performance experimentation for training AI models and AI inference workflows for deployment of multi-domain, multi-AI applications in smart hospitals. We will walk through the details of Clara Application Platform capabilities and our ecosystem partners. Using standardized tools for data management and annotation, model creation, validation, and deployment - Clara Imaging tools along with its ecosystem collaborators lower the barrier to adoption of AI in the medical imaging ecosystem.","Prerna Dogra, Product Manager, Clara Application Framework, NVIDIA",Healthcare & Life Sciences
Building Blocks for Machine Learning Integration into Clinical Workflow [S22189],"Applications of machine learning in radiology image analysis continue to grow at an increasing pace. For these tools to make an impact in diagnostics, they need to be well integrated into a clinical workflow. We'll review the radiology diagnostic interpretation process and the role of several machine-learning algorithms that support radiologists in this effort. We'll then focus on seven generalizable building blocks that are needed to integrate algorithm results into clinical workflow, with roles ranging from quality control and results presentation to error correction and active learning. We'll discuss current standards and the need for new standards, and highlight our experience in applying these algorithms and building blocks in a large cancer center.","Krishna Juluru, Director, Radiology Informatics, Memorial Sloan Kettering Cancer Center",Healthcare & Life Sciences
"Building Optimized, Low-Cost, Scalable Health-Care Enterprise Deep Learning Services Platform with NVIDIA TensorRT Inference Server and Kubernetes [s21570]","We'll illustrate how NVIDIA TensorRT Inference Server and Kubernetes helped us resolve several issues and build a scalable, low-cost and high-performance solution. Deep learning inference services are fundamentally different from web services and traditional machine learning services. DL services often require GPUs, and one must understand demand and GPU utilization so that load can be efficiently balanced across available inference resources. DL models may require significant compute and memory resources, and the need for serving multiple models and model versions compounds the complexity of a balanced inference deployment. Often, pre- and post-processing run on CPUs, while model inference runs on GPUs, so it is important to decouple them in order to be able to scale GPU and CPU resources independently. Health-care services also have rigorous security requirements and often require on-premises deployment.","Galina Grunin, Distinguished Engineer, Optum",Healthcare & Life Sciences
Clara Developer Day: Clara Train SDK Performance Walkthrough and Deep Dive [S22717],"In this session, developers and data scientists will learn about the latest performance feature in Clara Train v3.0. There will be a deep dive session walk-through for how to enable different features on a dummy example as well as real segmentation task.","Ahmed Harouni, Solutions Architect, NVIDIA",Healthcare & Life Sciences
Clara Developer Day: Federated Learning using Clara Train SDK [S22564],"Federated Learning techniques enable training robust AI models in a de-centralized manner – meaning that the models can learn from diverse data but that data doesn't leave the local site and always stays secure. This is achieved by sharing model-weights or partial model weights from each local client and aggregating these on a server that never accesses the source data. In this session we will deep dive into the federated learning architecture of latest Clara Train SDK. We will cover the core concepts of Federated Learning and the different collaborative learning techniques. Afterward, we will dive deeper into how using the Clara Train SDK enables privacy-preserving Federated Learning. This session will also cover the ease of bringing up Federated Learning clients and establishing communication between various clients and a server for model aggregation.","Nicola Rieke, Senior Deep Learning Solution Architect - Healthcare, NVIDIA",Healthcare & Life Sciences
Clara Developer Day: Getting Started with Clara Train for High Performance & Iterative Experimentation with AutoML [S22563],"In this session, developers and data scientists will learn how using Clara Train SDK accelerates and standardizes model development for medical imaging. We will cover the SDKs core concepts and capabilities to define a training workflow with the option to “bring your own components”. The session will also include a hands-on deep dive on how optimize hyper-parameter using AutoML.","Ahmed Harouni, Solutions Architect, NVIDIA",Healthcare & Life Sciences
Clara Developer Day: Scalable and Modular Deployment Powered by Clara Deploy SDK [S22565],"Clara Deploy SDK provides a reference framework for developers, data scientists and engineers to make seamless the process to turn trained AI models into operators. These operators can be stitched together to define an AI deployment pipeline, using reference DICOM adapters and sample pipelines that can interface with a medical imaging environment, like a PACS or VNA. In this session, we will do a walk-through of platform features that enable scalable deployment of multiple AI based pipelines in a hospital IT-like infrastructure. We will also do a hands-on session enabling end-end deployment of a Clara Train model. The users will interact with the SDK to deploy reference pipelines and learn how they can use the modular nature of the overall framework to power deployment of AI models in medical imaging workflows.","Jesse Tetreault, Solutions Architect, NVIDIA",Healthcare & Life Sciences
Computer Vision in Agriculture: Racing with Pests and Diseases [P22001],"Modern technologies of GPU computing and machine learning allow us to create an autonomous system of greenhouse plant condition control. We combined multiple sensor systems with a photo/video surveillance system, which allows us to create a comprehensive control system helpful for early detection of pests and diseases. We strive to create a stable and reliable solution for AI-based early plant disease detection, disease classification, pest detection, and plant development monitoring. We present our working solutions for vertical farming and a prototype of a more general system.","Ivan Molodtsov, Head of Machine Learning, Fermata",Healthcare & Life Sciences
Data-Driven Approach of Coronary Vessel Reconstruction Using X-ray Angiography [P21799],"Coronary artery disease is typically diagnosed using X-ray angiography. The percent stenosis, or narrowing of the blood vessel, is estimated via visual inspection of 2D angiography images; however, image artifacts and non-ideal projection angles can lead to miscalculation of disease severity. To address this problem, we propose a data-driven method to reconstruct the 3D geometry of the coronary vessels. A convolutional neural network was trained to segment vessels from angiography images. The segmented binary images were subsequently used as input images for several 3D reconstruction algorithms. The reconstructed 3D geometry can be used as input data for computational fluid dynamics analysis to characterize the hemodynamics of the diseased vessel and thus further improve diagnostic accuracy.","Kritika Iyer, Ph.D. Candidate, University of Michigan",Healthcare & Life Sciences
Data-Efficient Weakly Supervised Histology Classification Using Contrastive Predictive Coding [P22025],"Neural network classification models can be trained on weakly annotated medical imaging data using multiple instance learning (MIL). However, due to weak supervisory signals, direct application of MIL suffers from overfitting when faced with limited labeled data and the network is unable to learn rich feature representations. To overcome such limitations, we propose a two-stage semi-supervised approach that combines data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and attention-based MIL. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95% and an area under the ROC curve of 0.968 on a breast cancer classification dataset. We evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework using limited labels and with the feature encoder frozen.","Ming Yang Lu, Research Intern , Computational Pathology, Brigham and Women's Hospital, Harvard Medical School",Healthcare & Life Sciences
"Deep Learning-Aided Label-Free, Real-Time and Time-Lapse “Cell Visualization” Technology that Enables Live/Dead Cell Discrimination and Counting [P21952]","""Cell visualization"" is a new technology that can predict cell properties, such as cell life and death, from bright-field cell images. It's necessary to build a deep-learning model in which the relationship between a teacher cell image, such as fluorescence labeling indicating cell properties, and the corresponding bright-field cell image is finely learned. Inputting unknown bright-field cell images to the constructed learning model generates a pseudo-fluorescent labeling image showing the characteristics of the cells, enabling ""visualization of cells."" The present technology may replace many cell assays in drug discovery by solving the invasiveness of fluorescence-based cell assays. This technology also realizes real-time monitoring of cell quality. This innovative cell digitization technology is expected to become essential in the fields of drug discovery and regenerative medicine.","Tamio Mizukami, Professor, Nagahama Institute of Bio-Science and Technology",Healthcare & Life Sciences
Deep Learning in Health Care: from Voicebots to Disease Prediction [S21128],"We will focus on a few use cases where deep learning and NVIDIA GPUs help transform health care operations, automate prior authorization processes to reduce operational costs, suggest the next-best action to patients in order to help them manage their chronic conditions, and control call center volumes while increasing customer NPS scores. United Health Group receives over 30 million provider calls each year, out of which over 7 million result in call transfers. We've used a combination of deep learning models to identify the predictors of future calls and the providers likely to make them, enabling us to proactively reach out to them to prevent the incoming calls. If an incoming call is, however, detected, we use NVIDIA’s Nemo ASR / NLP framework to analyze the purpose of the call in real time and optimally route it to the appropriate agent. We'll also discuss our early successes in applying NVIDIA’s OpenSeq2Seq and Nemo frameworks to create voicebots — systems that users can interact with using voice. The quality of audio (smartphone versus phone line), domain (general versus clinical), speaker accents, and so on matter. We'll include an end-to-end overview of the tooling that we created for incremental data collection and model fine tuning on that data, along with metrics of quality and performance benchmarks. Finally, we'll cover our deep learning work on Next Best Action, where we use patients' history to predict the poly-chronic medical conditions and identify high-risk individuals. We then recommend the preventative next-best action, such as an ER visit or a hospitalization.","Julie Zhu, Distinguished Engineer/Chief Data Scientist, United Health Group, Optum Technology",Healthcare & Life Sciences
"Deep, Self-Supervised Learning for Patient-Specific Anomaly Detection in Stereoelectroencephalography [S21962]","We'll discuss methods for accurate, real-time detection of anomalous events in medical time-series data, with particular application to stereoelectroencephalographic (SEEG) interpretation and event localization for patients with epilepsy. Previous deep learning-based approaches to detecting EEG anomalies have been plagued by high false-positive rates and inability to detect anomalous events that fall below a statically-set threshold. You'll learn the benefits of a nonparametric approach that utilizes a dynamic thresholding method for event detection, producing significant performance improvements. We'll discuss basic approaches and challenges in anomaly detection in medical time series data, limitations encountered by previous deep-learning approaches to anomaly detection, and how to apply a nonparametric dynamic thresholding procedure to improve performance and mitigate false positive results.","Anthony Costa, Director, Sinai BioDesign, Icahn School of Medicine at Mount Sinai",Healthcare & Life Sciences
De Novo Protein Design of Epitope-Directed Inhibitors [s21348],"Protein drugs have revolutionized modern cancer therapeutics, as protein-based binders can effectively target molecules that are otherwise undruggable by small molecules. Presently, such binders are based on monoclonal antibodies, which are developed and engineered through lengthy and resource-intensive processes of iterative optimization that are empirically guided. Conversely, de novo protein design can offer a rational means for generating new binders with bespoke scaffolds, guided by physics-based computations. Here, we'll present our work on developing a purpose-built, GPU-accelerated computational pipeline for designing protein-based binders de novo. As a proof of principle, we designed proteins that target a key modulator of cancer metastasis. Our experimental characterization of only a few design candidates resulted in binders with strong binding affinities. Solving the structure of one design showed atomic-level agreement between the design model and the determined structure.","Mohammad ElGamacy, Postdoctoral Research Fellow, Friedrich Miescher Laboratory of the Max Planck Society",Healthcare & Life Sciences
"Deploying FDA-Cleared, TRT-Powered AI Radiology Products to Improve Quality and Productivity in Clinical Radiology [S22400]","SubtlePET and SubtleMR are FDA-cleared AI software products developed by Subtle Medical that use deep learning to significantly improve the image quality and efficiency for PET-CT and MRI exams. We'll introduce how Subtle develops AI that is generalizable and seamlessly deployed in clinical settings. Join our session to:
Learn how to clinically evaluate and deploy AI software solutions at multiple hospitals and imaging centers, through Subtle’s experience of working with Stanford University, the University of California at San Francisco, Hoag hospital, U-C San Diego, Middlesex, RadNet, and others;
Understand how attention models and improved deep-learning architectures improve model performance;
Learn benefits of training algorithms on NVIDIA DGX Station and DGX-1 systems, and how it provides flexibility and efficiency from prototyping to product;
Learn how integrating with NVIDIA TensorRT can accelerate inference; SubtleMR will share there experience where turnaround time is critical, TRT provided additional speed of up to about 8.8x; and
Learn techniques to show how to show evidence of significant clinical values and financial ROI to customer hospitals and imaging centers.","Enhao Gong, Founder and CEO, Subtle Medical",Healthcare & Life Sciences
Distributed Deep Learning for Automatic Disease Detection Systems [P22078],"Deep neural networks and other deep-learning approaches are providing diagnostic capabilities on a par with medical specialists. If deployed in the field, these DL applications and devices can help to detect health conditions early and develop preventive approaches. However, deploying such systems requires large compute infrastructure. To address the infrastructure issues, I developed a distributed cost-effective approach using edge devices and a cloud-based central hub for better predictions. To test its effectiveness, I applied it to diagnosing eye conditions using fundus images.","Ananya Gangavarapu, Student, Princeton International School of Mathematics and Science",Healthcare & Life Sciences
Empowering Virtual Reality and Machine Learning in the Hospital [S21472],"A patient's journey through the hospital system involves long-established steps that, collectively, aim to define and provide the best treatment strategy. Two critical actors in this journey are the radiologist and the surgeon. They communicate via the patient's medical image. We'll discuss how we bring new GPU-based technologies, such as virtual reality and machine learning, to this very traditional place of work. We'll outline the degree to which these technologies have been useful in our medical collaborations, as well as how they can optimize outcomes for the patient.","Mohamed El Beheiry, Lead Developer, Institut Pasteur",Healthcare & Life Sciences
Federated Learning for Medical Imaging: Collaborative AI without Sharing Patient Data [S21536],"While deep neural networks have shown promising results in various medical applications, they highly depend on the amount and diversity of the training data. In the context of medical imaging, this poses a major challenge because patient data needs to be protected and cannot easily be shared. The training data that is required to train a reliable and robust algorithm may not be available in a single institution due to the low incidence rate of some pathologies and limited numbers of patients. At the same time, it is often not feasible to collect and share patient data in a centralized data lake due to patient privacy concerns and regulations. Federated learning — as a collaborative machine learning paradigm — combined with an advanced privacy-preserving mechanism has the potential of solving this issue: models can be trained across several institutions without explicitly sharing patient data. When implementing and deploying a federated learning system into the real-world medical imaging ecosystem, participants can authenticate and communicate securely, and exchange model weights efficiently, enabling model training to be successful. In this talk, we present an introduction to the core concepts of federated learning and discuss the benefits as well as the unique considerations and challenges of implementing a federated-learning system in the context of health care.","Nicola Rieke, Senior Deep Learning Solution Architect - Healthcare, NVIDIA",Healthcare & Life Sciences
Fostering a Strong Ecosystem for AI in Medical Imaging [S22631],"In order to fully leverage the possibilities that AI offers to drive higher-value health care, we need to create an effective collaboration between physicians and developers, policymakers and payers, and most importantly the patients we will serve. We'll explore ways in which those collaborations are already happening and highlight gaps and opportunities. The speaker, a practicing radiologist specializing in breast imaging, will discuss the ways in which she sees AI impacting her practice now and in the future.","Geraldine McGinty, Chief Strategy and Contracting Officer, Weill Cornell Medicine",Healthcare & Life Sciences
Fully Automated Blood Analyzer Driving Early Detection for Leukemia Based on Cytomorphology [P22070],"The chances of leukemia survival depend on a variety of factors, including early detection and response to treatment. Cytomorphology introduces the methodology to characterize blood cell morphology to detect leukemia in the early stage. We developed a fully automated blood analyzer based on cytomorphology to count all types of different white blood cells, red blood cells, and blood platelets. The whole workflow of this system includes sample delivery, screening, segmentation, and classification. Compared with the other leading manufacturer, such as CellVision, the segmentation and classification in our system is driven by deep learning instead of pattern recognition, which lets our results achieve more than 95% accuracy based on the validation of a real dataset counted by doctors from a top hospital. It means that our system can be the first real-world health-care AI product in hematology. We'll introduce more detail about our workflow and AI technology accelerated by NVIDIA advanced GPU.","Jie Wang, AI Computing Specialist, Shanghai Jiao Tong University",Healthcare & Life Sciences
Generating Microscopic Phase Images with Deep Learning [P22394],"This poster will present a deep-learning approach for generating microscopic phase images from brightfield images, contrasting it with current approaches. We'll highlight examples of novel techniques developed at PerkinElmer using supervised and self-supervised approaches to tackle common problems faced by classical approaches. We'll also discuss the challenges of building and testing these generative models for medical imaging and drug discovery applications.","Abdul Al-Haimi, Software Research Lead, PerkinElmer",Healthcare & Life Sciences
GPU-Accelerated Animated Volume Rendering of Isogeometric Analysis Results [P22069],"Development of isogeometric analysis (IGA) has enabled tighter integration of engineering design and computational analysis. The core idea of IGA is to use same NURBS (Non-uniform rational B-splines) basis functions for representation of geometry in CAD and the approximation of solution fields in FEA. However, visualizing the results of volumetric IGA is compute-intensive; hence, current methods are not interactive. We developed a modified ray-casting and voxelization method for visualizing volumetric NURBS, which provides better interactive performance. This process has been highly parallelized using the GPU to produce interactive animated results in real time. We present an example of the utility of the approach in visualizing results of cardiac simulations.","Harshil Shah, Graduate Student, Iowa State University",Healthcare & Life Sciences
GPU-Accelerated Genome Assembly: A Deep Dive into Clara Genomics Analysis SDK [S21968],"We'll present de novo genome assembly for long DNA reads using the Clara Genomics Analysis SDK and dig deep into the SDK implementation. We'll discuss the suitability of GPUs for genomics workloads and present algorithms suitable for massively parallel systems. We'll also review the challenges we faced while implementing the algorithms in CUDA, and present the solutions used in cudaAligner, cudaPoa, and cudamapper.","Andreas Hehn, Developer Technology Engineer, NVIDIA",Healthcare & Life Sciences
"High Throughput Cryo-Electron Microscopy and Cryo-Electron Tomography Powered by GPU at the University of California, San Francisco [S21696]","As early as in 2009, GPU-based computing was introduced at the University of California, San Francisco (UCSF) to reconstruct electron tomographic volumes. Today, 10 years later, high-resolution cryo-electron microscopy (CryoEM) and cryo-electron tomography (CryoET) powered by state-of-the-art GPU technology are routinely used worldwide in structural biology. We'll present the development of GPU-based applications at UCSF to solve critical challenges in CryoEM and CryoET — namely, beam-induced motion, cryoET alignment, and deep-learning based de-noising of cryoEM low-dose images. You should be familiar with back- and forward-projections, Fourier Transforms, C++, and CUDA programming.","Shawn Zheng, Bioinformatics Specialist, Howard Hughes Medical Institute, University of California San Francisco",Healthcare & Life Sciences
Holistic AI-Enhanced Workflows in Radiology [S21440],"We'll highlight the advantages of a holistic workflow in radiology, the opportunities and challenges of AI implementation in diagnostic workflows, and their impact on treatment decisions and patient outcomes. AI will have a tremendous impact on the way we think and work in medicine. Diseases are complex pathological processes and more than one algorithm is often needed to answer relevant medical questions. This requires a well-managed orchestration of the reporting workflow. We'll introduce the Smart Reporting platform as an innovative tool for synoptic AI-enhanced reporting, which massively improves interdisciplinary communication. Leveraging on NVIDIA Clara and GPU computing, we'll also present a novel pipeline for prostate cancer imaging, tumor detection, automatic report generation, communication of results, and improved treatment decisions.","Alvaro Sanchez, Principal Software Engineer, Smart Reporting GmbH",Healthcare & Life Sciences
Improving Classification of Lymph Node Histopathology Patches Using Semi-Supervised Classification-GAN (SSC-GAN) [P21984],"The goal of our Semi-Supervised Classification-GAN (SSC-GAN) on histopathology images is to use generated synthetic images to aid in data augmentation and improving classification accuracy, beyond the regular classifiers such as CNNs, where access to annotated data is limited.","Aditya Mitkari, Machine Learning scientist, Onward Health",Healthcare & Life Sciences
Improving CNN Performance with Spatial Context [S21388],"Deep learning with convolutional neural networks (CNN) is a powerful technique with wide-ranging applications. It has largely replaced traditional computer vision as the go-to method for solving image-analysis and classification problems. At its essence, however, training a CNN is an enormous global optimization problem which, like all optimizations, can fall victim to local extrema. We'll discuss ways of mitigating this issue using computer vision to add spatial context information to restrict the domain of optimization. These techniques not only speed up the training, but also improve the overall performance of the networks. We'll demonstrate results on real-world classification and segmentation problems.","Daniel Russakoff, Co-Founder and Principal Scientist, Voxeleron",Healthcare & Life Sciences
Insight-Driven Machine Learning Design with Human Expert Collaborations [S21636],"The fundamental breakthroughs in machine learning, and the rapid advancements of the underlying deep neural network models have enabled the potential use of these systems in specialized, high stakes domains such as healthcare. However, despite this remarkable progress, the design of machine learning systems remains laborious, computationally expensive and opaque, sometimes resulting in catastrophic failures and significantly hindering their ability to work with human experts, who play critical roles in these settings. In this talk, I overview steps towards a more informed, intuitive design of machine learning systems, and methods to facilitate collaboration with human experts. I develop tools that enable the quantitative analysis of the complex hidden layers of deep neural networks, which in turn provides both fundamental insights and informs algorithms for efficiently training these systems. I demonstrate how these trained systems can be adapted to work effectively with human experts, resulting in better outcomes than either entity alone.","Maithra Raghu, Research Scientist, Google Brain",Healthcare & Life Sciences
Machine Learning Cell Phenotypes with Immuno-Fluorescent Cancer Tissue [P22105],"Multiplexed immuno-fluorescent tissue imaging enables precise spatial assessment of protein expression in medical resection specimens. However, tissue sections are stained with a mixture of antibodies, DNA, and RNA markers. Detecting weak or broken edges due to fluorescent membrane-staining artifacts between touching or overlapping cells is a long-studied problem, and is an active research topic in biomedical image analysis. Sometimes, even humans can't visually detect these kinds of edges. We've built a GPU client-server and developed a hybrid system combining the stochastic random-reaction-seed (RRS) method and deep neural learning U-net to identify cell membranes accurately and automatically. Furthermore, we've designed a high-performance AI pipeline in quantifying spatial distribution of cell phenotypes from tissue images with various complexities.","Alvason Zhenhua Li, Postdoctoral Research Fellow, Fred Hutchinson Cancer Research Center",Healthcare & Life Sciences
Making Radiology AI Models More Robust: Federated Learning and Other Approaches [S22037],"Learn about the key types of clinical use cases for AI methods in medical imaging and the critical challenges and progress in applying AI in these applications. We describe current challenges to creating robust AI models, such as insufficient quality labeled data and access to data. Next, we'll describe recent AI projects that tackle the challenges, including weak/observational learning and federated learning.","Daniel Rubin, Professor, Stanford University",Healthcare & Life Sciences
Manipulating the StyleGAN Latent-Space: H&E Image Synthesis for Prostate Cancer Research [P22077],"The open-source contributions of NVIDIA research projects have been accelerating the effectiveness of generative adversarial networks since their popularization in 2014. The StyleGAN (Dec 2018) enables detailed control over the generator’s captured learnings. We explore the generator’s learned assignment of image features in the medical domain. Today, prostate cancer is one of the most common types in men. Diagnosticians examine slices of prostate tissue to analyze cancer growth and determine treatment strategies. Staining techniques provide unique lenses for diagnosis, highlighting stroma patterns, lumen areas, epithelium groupings, and nuclear areas. In our experiment, we input a dataset of H&E stained prostate tissue covering the entire spectrum of the disease. During model training, the network creates a mapping of all image features into a latent space. We aim to discover direction vectors between cancer-relevant morphological features.","Gagan Daroach, Undergraduate Researcher, Milwaukee School of Engineering",Healthcare & Life Sciences
Medical Volume Raytracing in Virtual Reality [S22030],"Raytracing voxels in medical images is a relatively new technique that lets us see medical images in a new light. It allows for creating realistic-looking light effects, like soft shadows. Exploring medical images in virtual reality benefits because these advances make objects look more real, making it easier for a physician to interpret what they are seeing. We'll discuss the challenges with doing volume raytracing in VR, and will demonstrate a solution in CUDA involving rendering to an eye-tracked foveated/warped space. We'll discuss how we can stream this warped space from a server to a head-mounted display, and how to effectively de-noise the results for VR. We'll also show how to use the extra GPU budget that we created by foveated/warped rendering to improve visuals by including better material choices based on DL-generated label maps and define less stair-stepped implicit surfaces based on tricubic interpolation.","Jeroen Stinstra, Dev Tech Medical Imaging, NVIDIA",Healthcare & Life Sciences
Multi-Task Learning for Sparse Sensor Body Tracking [P22340],Assistance and rehabilitation technologies built on inertial measurement unit-based human motion trackers often use a full-body sensor set. This is necessitated by the bio-mechanical model inspired by the skeleton structure. Reducing the number of sensors will make such technologies more affordable and easier to use for non-expert and unmonitored uses. We explore solutions and demonstrate that it's viable to reduce the number of sensors required for credible body segment acceleration and joint angle tracking. This is achieved by statistical learning on the reduced sensor set by developing inferences based on neural network and signal processing pipelines.,"Aditya Tewari, Machine Learning Scientist, Xsens Technologies",Healthcare & Life Sciences
NVIDIA Quadro RTX for Healthcare - Improving Patient Outcomes [S22422],This talk covers how Quadro RTX features like real-time ray tracing and AI can reshape healthcare and the life sciences disciplines that support basic research leading to new treatment options and better patient outcomes,"CARL FLYGARE, Quadro Product Marketing Manager, PNY Technologies",Healthcare & Life Sciences
PDGAN: An End-to-End Parkinson's Disease Data Analysis and Diagnosis System Using Deep Learning [P21110],"PDGAN is a deep-learning-powered tool capable of detecting early signs of Parkinson's disease — a prevalent disease that affects millions of people worldwide. Using MRIs, PDGAN can classify patients in the earliest stages of Parkinson's Disease with 96% accuracy. PDGAN uses a unique technique to solve the diagnosis problem, using generative adversarial networks to synthetically create MRI scans to augment the training dataset. Our poster describes the technical aspects of the dataset, the pipeline of deep-learning tools used to solve the problem, additional features that PDGAN uses that traditional deep-learning solutions don't utilize, and the benefits that each of them bring. It discusses using NVIDIA tools to solve problems that plague many machine-learning problems, including a slow training process and the lack of adequately large data using novel GAN-powered techniques.","Neeyanth Kopparapu, High School Student, Thomas Jefferson High School for Science and Technology",Healthcare & Life Sciences
Practical Guidelines for Optimizing and Accurate Sizing of Medical Imaging Workflows [S21997],"Deep dive into the various considerations that could be critical to substantially improve existing medical imaging workflows. We'll motivate our discussions through a detailed analysis of two common medical imaging workflows: 2D classification and 3D segmentation. Our results suggest that controlling for aspects such as i/o format, selection of hyper-parameters, and mixed-precision training could all be key to maximizing hardware performance and reducing turnaround time for experiments. Furthermore, we aim to discuss other strategies, such as learning-rate warmup and scaling, effect of optimizers, scaling to multiple GPUs, and their potential effects on training throughput. We were able to show a 5x improvement for the 2D classification task through our ablation experiments. We'll use these results suggest best practices learned, and also build a sizing calculator for providing quantitative insights for hardware investments.","Anas Abidin, Solutions Architect, NVIDIA",Healthcare & Life Sciences
Reconstruction of Under-Sampled Cartesian Data Using Deep Learning [P21927],"Magnetic resonance imaging (MRI) is a non-ionizing medical imaging modality that provides excellent contrast information about human tissues. One of the limitations of MRI is its long data-acquisition time. One way to reduce the MRI scan time is to collect less data that introduces aliasing in the resulting MR image. Dedicated MRI reconstruction algorithms can be used to remove the aliasing effects. Under-sampled Cartesian data, in conjunction with an advanced reconstruction algorithm, has been used in literature to get the aliasing-free image. We propose a convolution neural network (CNN)-based solution to reconstruct the MR image from under-sampled MRI data, thus helping to reduce the scan time. We use artifact power and signal-to-noise ratio to quantify the reconstruction quality. We compare the results to the state-of-the-art SENSE reconstruction algorithm.","Taquwa Aslam, M.S. Student, COMSATS University Islamabad, Islamabad Pakistan",Healthcare & Life Sciences
Rethinking Impact Factor: an NLP-Driven Metric and Pipeline Using Generalized Autoregressive Pretraining on Medical Journals for Granular Knowledge [S21552],"Dramatic advances in NLP have reinvented performance on public leaderboards, such as the Stanford Question Answering Dataset and decathlon superGLUE. Nominally, approaches follow transformers-based architectures in a pretrain-finetune paradigm, with the bulk of compute in the pretrain phase. Where previous studies have elucidated finetune paradigms for recurrent neural network architectures, ours examines a multi-phase NLP paradigm for realizing expert-level domain-specific performance, specifically for the clinical task of unplanned 30-day hospital readmission. With exhaustive GPU studies and Bayesian optimization, in part with the NVIDIA Clara Train platform, we'll show that systems are only as good as what they read. From 20 top medical practice journals over the past 90 years, we determined a novel AI-impact factor for the clinical task that guides to state-of-the-art AUC of 0.74. We'll review best practices on training modern transformer-based architectures for medicine.","Leo Tam, Senior Applied Research Scientist, NVIDIA",Healthcare & Life Sciences
Segmentation-Guided Pelvis Fracture Detection in Pelvis X-rays [P21979],"Pelvis fractures represent approximately 3% percent of all skeletal injuries and can be observed in any group of patients. Like much trauma, there is a bimodal distribution, with younger male patients involved in high-energy trauma and older female patients in minor trauma. In this work, we utilize GPU computing to process high-resolution pelvis X-ray images and segment into pelvis anatomical regions. Then, we train a binary classifier on segmented anatomical region to detect fracture.","jalaj jain, CTO, imera.ai",Healthcare & Life Sciences
Segmentation of Organs at Risk in Chest Cavity Using 3D Deep Neural Network [P21943],"Our work considers the problem of segmentation of organs-at-risk in planning radiotherapy of lung and esophageal cancer. To solve this problem, we developed a system based on a 3D implementation of the U-Net neural network architecture with ResNet-50 encoder. One of the main problems of segmentation of 3D images is the limitation of computing power. We propose a multi-dimensional approach that effectively uses the available infrastructure for processing large image data. Overfitting due to the small size of the dataset is another important problem. We solve this using input mixup for regularization of neural networks. To train the deep-learning models, the NVIDIA TITAN X Pascal and NVIDIA Tesla V100 were compared, with and without Apex Optimization. The results demonstrate that the best performance was obtained using NVIDIA Tesla V100 16Gb with Apex Optimization.","Maksym Manko, Research Engineer, Ciklum",Healthcare & Life Sciences
*Top 5 Poster Nominee - MolecularRNN: Generating Realistic Molecular Graphs with Optimized Properties [P22377],"We'll introduce MolecularRNN, the graph-generative model for molecular structures. Designing new molecules with a set of predefined properties is a core problem in drug discovery. There is a growing need for de-novo design methods. Our model generates diverse realistic graphs after likelihood pretraining on a big database of molecules. We perform an analysis of pretrained models on large-scale generated datasets of 1 million samples, then tune the model with a policy-gradient algorithm provided with a critic that estimates the reward for the property of interest. We see a significant distribution shift to the desired range for lipophilicity, drug-likeness, and melting point, outperforming state-of-the-art works. With the use of rejection sampling based on valency constraints, our model yields 100% validity. We'll show how invalid molecules provide a rich signal to the model through the use of structure penalties in our reinforcement learning pipeline.","Mariya Popova, Ph.D. Student, Carnegie Mellon University",Healthcare & Life Sciences
