title,description,company,industry
3D Analysis Data Generation from X-ray Data for HealthTech by DGXs [P22304],"In Japan, research on regenerative medicine is advancing, various levels of treatment are advancing, and laboratories dealing with nearly 1,000 regenerative medicine cells are starting to appear every week. Research in these regenerative treatments requires new medical imaging—to increase the resolution of two-dimensional image data, for example. Rather than discovering new indicators that map annotations, it is easier to use existing indicators or to generate images for use. Currently, a 3D image is generated from a 2D image by X-ray, and a 3D curved surface learned by a Tesla chip is developed to generate a realistic 3D image. By generating even sliced images, we provide digital data materials that can be used as reference for proceeding to MRI after X-ray imaging.","Shigehisa Omatsu, CEO, Stellaplace, Inc.",Healthcare & Life Sciences
60-fps Pose Estimation on Jetson Nano: Furinkazan Pose [P21911],"We present our pose estimation technology, named Furinkazan Pose. To our best knowledge, it's the fastest pose estimation in the world that can run perfectly on edge devices. Furinkazan Pose Lite, a lite version of the technology, runs over 4x faster (over 7x using TensorRT) than the latest OpenPose on GPU machines, and over 400x faster than OpenPose on CPU-only machines. Its model file is only 5 MB. We'll also present the standard version of Furinkazan Pose which is more accurate but still much faster than OpenPose. We'll show a live demo of the pose estimation running up to 60 fps on Jetson Nano so that you can see how accurate this super fast technology is for many potential edge-based applications.","Xiang Ruan, Founder & CEO, tiwaki Co., Ltd.",Manufacturing
Accelerating Large Seismic Simulation Code with PACC Framework [P21901],"The pipelined accelerator (PACC) helps lower the hurdle for implementing out-of-core stencil computation, such as large seismic simulations. However, the out-of-core applications themselves are facing data-movement bottlenecks because improvement of accelerators dwarfs that of interconnects. In this poster, we introduce temporal blocking techniques to reuse on-chip data, and propose a data-mapping scheme to eliminate data movement on the host side. The data-mapping scheme accelerates the program by 2.5x compared to previous work and by 35x compared to an OpenMP-based program. However, performance is still bound by data movement between the host and device, so we need to come up with further data-centric strategies. Moreover, the degradation in execution time of PACC code is about 25% compared to an in-core OpenACC code, which should be reduced if we can design further data-centric strategies.","Jingcheng Shen, Ph.D. Student, Osaka University",Higher Education / Research
Accelerating the Singular Value Decomposition: Measuring SVD Performance for Small Matrices [P21776],"Advanced algorithms for spatio-temporal signal processing of data from a phased sensor array often require singular value decompositions (SVD) of a very large number of complex-valued matrices of a relatively small size. Our poster describes a GPU-implemented SVD that we custom-designed for such signal processing applications in order to enable real-time performance. We compare our SVD with tools available in the cuSolver, MKL, and MAGMA libraries, and we document a substantial performance improvement on batches of small square matrices.","Charlotte Kotas, Research Scientist, Oak Ridge National Laboratory",National Labs / Research Computing Centers
Accelerating Unsupervised SAR Polarimetric Image Segmentation by Parallel Wishart Classifier [P21999],"Our poster presents the unsupervised segmentation of SAR polarimetric images. These images are multi-band areal images of the Earth captured by satellites with special sensors. The process required to segment these images is massive, and the task of segmentation is crucial, as through it we needed to extract important physical information of the area under observation, such as the geometric orientation, structure, shape, and configuration. We propose a much faster parallel implementation of Wishart Classification Based technique that outperforms the vanilla methods by 240%.","Shivam Patel, Visiting Research Student, University of Cambridge",Aerospace / Defense / Government
Acceleration of Test Data Quality Assurance Technology Using Neuron Coverage [P21809],"“Neuron coverage test” is one way to test quality in deep-learning systems. We've implemented “DeepXplore,” which is a quality test method for DL systems that applies our unique high-speed inference library. DeepXplore is a framework that can systematically test DL systems and automatically generate misrecognition images from the coverage rate of the trained model and the output difference of the comparison model. However, a large amount of inference would be necessary to automatically generate these misrecognition images, and that could require a lot of processing time. We sped up processing by using our unique high-speed inference library to implement DeepXplore.","Yuki Shindo, Staff, Computermind Corp.",Software
Acceleration of Wavefront Analysis Using Zernike Polynomial Fitting [P21849],"Zernike polynomial fitting can analyze the wavefront map of biological cells with uniform contents. Aberrations not only indicate changes in the wavefront after passing through cells, but also provide angular position for tomogram reconstruction. However, Zernike polynomial fitting for wavefront analysis is time-consuming. To raise efficiency, we implemented Zernike polynomial fitting on a GPU card. We simulate a sequence of red blood cell phase maps with various rotation angles, and estimate the angles using the coefficients of defocus, vertical, and horizontal tilts from Zernike analysis. The error of angle estimation is under 0.7%, and we achieve video-rate processing at 128×128 pixels. This shows the possibility for implementing wavefront analysis on a GPU card and its benefit on tomogram reconstruction.","Yang-Hsien Lin, Ph.D. Candidate, National Taiwan University",Healthcare & Life Sciences
Accurate Multiple Sclerosis Lesion Segmentation Using Deep Learning [P21889],"We present results of a comparison of multiple deep neural networks (DNNs) performing image segmentation for multiple sclerosis (MS) brain lesions. MS is an autoimmune disease that leads to demyelinating lesions in the central nervous system. Measuring disease progression via brain magnetic resonance imaging (MRI) is an important part of managing MS. Manual segmentation of MRI brain lesions by radiologists is time-consuming and subject to high user variability. Our poster shows the results of using three different DNN architectures, trained using NVIDIA GPU. You'll learn about using neural network for medical image segmentation, particularly applied to the measurement of MS brain lesions. You'll also learn about different DNN architectures, including Inception-based convolutional networks and U-Net based networks, as well as techniques used to compare automated segmentation results to each other and to human expert segmentation.","Ethan Ocasio, Chief Technology Officer, Girls Computing League",Healthcare & Life Sciences
AceCAST GPU-Enabled Weather Research and Forecasting Model Development and Applications [P22064],"The Weather Research and Forecasting (WRF) model is an open-source, mesoscale numerical weather prediction system designed to serve both operational forecasting and atmospheric research needs. It is the most widely used regional weather forecasting model and a top 5 HPC application worldwide. TQI has implemented an OpenACC/CUDA-based version of WRF to take advantage of NVIDIA GPUs. By utilizing GPUs, the measured performance benefits enable better forecasting through higher resolution, temporal/geographical extents, and so on. Our poster discusses the GPU implementation of the model as well as performance benchmarks demonstrating the model’s practical performance benefits. TQI has also developed a cloud-based solution for running end-to-end AceCAST GPU-WRF workflows on AWS. This provides a solution for a wide range of users who would otherwise not have access to GPU-based compute resources, and automates a highly complex process that is a significant barrier for researchers and operational weather forecasters.","Samuel Elliott, Director of NWP Solutions, TempoQuest Inc.",Software
Achieving Proportional-Fair Scheduling on ~100 μs Time Scale for 5G NR [P22313],"5G NR is designed to operate under a broad range of frequency spectra and to support new applications with extremely low latency. To support its diverse operating conditions, a set of different OFDM numerologies has been defined in 5G standards. Under these numerologies, it's necessary to perform scheduling with a time resolution of about 100 microseconds. This requirement poses a new challenge that doesn't exist in LTE and can't supported by any existing LTE schedulers. This poster presents a proportional-fair scheduler design that can meet the ~100 μs real-time requirement in 5G NR. The key ideas include decomposing the scheduling problem into a large number of small and independent sub-problems and selecting a subset of sub-problems from the most promising search space to fit into a GPU. Implementation on an NVIDIA Quadra P6000 GPU demonstrates that our design is able to achieve near-optimal performance while meeting the ∼100 μs time requirement.","Yan Huang, Research Assistant, Virginia Polytechnic Institute and State University",Telecommunications
Adversarial Learning of Deepfakes in Financial Accounting [P21923],"Nowadays, organizations collect vast quantities of accounting-relevant transactions, referred to as ""journal entries"" in enterprise resource planning systems. Aggregating those entries ultimately defines an organization’s financial statement. To detect potential misstatements and fraud, international audit standards demand auditors to directly assess journal entries using ""computer-assisted audit techniques"" (CAATs). At the same time, discoveries in deep-learning research revealed that machine-learning models are vulnerable to adversarial attacks. It also became evident that such attack techniques can be misused to generate ""’deepfakes"" designed to directly attack the perception of humans by creating convincingly altered media content. Research on such developments, and their potential impact on the finance and accounting domain, is still in its early stage. We show an adversarial attack against CAATs using deep-neural networks.","Marco Schreyer, Researcher, University of St. Gallen",Finance
A Framework for Measuring Hardware Gather-Scatter Support [P21887],"This poster describes a new benchmark tool, Spatter, for assessing memory system architectures in the context of indexed accesses. This type of memory operation is often used to express sparse and irregular data patterns. Gathers and scatters have widespread utility in modern HPC applications, including traditional scientific simulations, data mining and analysis computations, and graph processing. Spatter specifically measures gather / scatter (G/S) variations for multiple platforms, with several tunable backends, including CUDA and OpenMP, and provides comparison metrics for different sparse access patterns. We show how Spatter can be used to evaluate the recent improvements to G/S hardware on NVIDIA GPUs and CPUs, and show performance numbers for STREAM-like, uniform-stride, and application-derived memory access patterns.","Patrick Lavin, Ph.D. Student, Georgia Tech",National Labs / Research Computing Centers
AI Argus: A Unique Insight Into Logistics [P21812],"As of August 2019, AI Argus, the leading domestic intelligent video analytics platform powered by NVIDIA TeslaT4 and Xavier servers, has been deployed and applied in more than 200 distribution centers and sorting centers in China. We'll focus on algorithms such as loading-rate detection and violated-action pattern detection. AI Argus introduced the Package Lifecycle Tracking System (PLTS), which uses the whole SF's 310,000-channel camera video data to match the Operator's barcode data collector for locating the courier package on each operating node. It shows that the detection of damage caused by penetrating damage, moisture, wrinkles/pressure is significant. We'll further develop and research product performance indicators based on T4 and Xavier. We expect that in the coming year, AI Argus will deploy thousands of edge servers and become the first truly large-scale edge computing platform in China's logistics industry.","Neo Song, Chief Engineer, SF Techology",Software
AI-Assisted Cell Tower Inspection with Drones and GPUs [P22287],"Dive deep into the deep-learning-based efficient inspection solutions using cloud computing with GPUs. We recently launched a drone-management platform called “docomo sky”. This platform has deep-learning-based AI analytical functions using GPUs, which enable us to maintain a lot of infrastructure, such as cell towers and bridges, more efficiently and safely. We've started using this application to inspect our cell towers in Japan. We'll introduce rust recognition on cell towers and show how efficiently GPUs have been improving our work, compared to CPUs alone. Moreover, we'll touch on the cost-effective cloud design using GPUs on Amazon Web Services for AI.","Issei Nakamura, Artificial Intelligence Engineer, NTT DOCOMO, INC.",Telecommunications
AI-Enabled Live 3D Video [P21837],"Imagine watching an event (game, wedding, etc.) on the computer or TV, live from home. Wouldn’t it be a powerful experience to dynamically change the field of view and experience the event from multiple angles? You could even “walk around” the scene and select the most interesting point of view. Minmini’s Felinity technology allows us to deploy edge AI devices in a scene and extract interesting features from the cameras (people, ball, vehicles, etc.), estimate their 3D location in space, and reconstruct the scene on the remote viewer’s device, resulting in a live 3D experience. Our poster describes the components of our 3D visualization technology using an example from the sports industry. We also discuss the current levels of performance and the fields in which products built with the technology could be used.","Manisha Srinivasan, Product Manager, Minmini Corporation",Media & Entertainment
AI for Agriculture: Estimating Vigor on California Vineyards [P21782],"Estimating the balance or vigor in vines, as the yield-to-pruning-weight relation, is a useful parameter that growers use to better prepare for the harvest season and to precisely manage the vineyard, achieving a specific-site plan for the cultural practices like pruning, debriefing, or budding. Traditionally, growers get this parameter by manually weighing the pruning and correlating it to the harvest weight from the same area. Since is a very manual and time-consuming task, growers usually just take a couple of samples and extrapolate this value to the entire vineyard, losing all the variability present in their fields, which leads to loss in grape quality and quantity. We've developed a computer vision-based algorithm that is robust to differences in soil, color of the plant, and light conditions to automatically estimate a plant's vigor.","Maria Pantoja, Assistant Professor, CalPoly SLO",Other
AI-Solver: Deep Learning-Based Platform for Real-time Simulations on Structured (Grid) and Unstructured (Mesh) Data Representations [P21974],"In this work, we build on our recent efforts in developing a deep learning-based AI platform that learns from simulation data to extract a general physics-based behavior, code-named the ""AI-Solver."" Importantly, we report on a new and distinctive feature in the AI-Solver, where we enable it to learn not only from structured data representation (that is, pixels/voxels), but to learn directly from the raw and unstructured data representation as provided in their native formation, 2D/3D meshes. We apply this new functionality for learning the deformation of objects when subjected to an external load; a problem widely considered when studying structure analysis in the field of finite element analysis. To our knowledge, this new and challenging capability, which is very important because it eliminates the strong reliance on a pixel/voxel-based data representation with potentially large memory and computational savings, is a first in the field of AI for engineering.","Ahmed Al-Jarro, Principal Researcher and Technical Lead , Fujitsu Labs of Europe, Ltd.",Other
ALFRED: Action Learning From Realistic Environments and Directives [P22310],"ALFRED is a benchmark for learning a mapping from natural language instructions and egocentric vision to sequences of actions for household tasks. Long composition rollouts with non-reversible state changes are among the phenomena we include to shrink the gap between research benchmarks and real-world applications. ALFRED consists of expert demonstrations in interactive visual environments for 25,000 natural language directives. These directives contain both high-level goals like ""Rinse off a mug and place it in the coffee maker"" and low-level language instructions like ""Walk to the coffee maker on the right."" ALFRED tasks are more complex in terms of sequence length, action space, and language than existing vision-and-language task datasets. We show that a baseline model designed for recent embodied vision-and-language tasks performs poorly on ALFRED, suggesting that there is significant room for developing innovative grounded visual language understanding models with this benchmark.","Daniel Gordon, Ph.D. Student, University of Washington",Higher Education / Research
An AI Solution for Thermographic and Optical Inspections in Electric Distribution Network Using Deep Learning-Based Software [P22048],"Our poster describes the overall time savings and cost reduction of mounting a deep-learning-based system on a terrestrial vehicle's rooftop. The vehicle's main objective is to capture and recognize images of overheating elements from the distribution power grid network. Initially, the vehicle was equipped with eight cameras to inspect both sides of the road, as well as the front view, enabling it to inspect hundreds of miles of power distribution lines without stopping and with no human operator. The result was a 94.4% gain in time for a 37-kilometer line track that was inspected in less than two hours when compared to the previous human process using a handheld camera, and also a system with a capability of identifying elements with a accuracy of 96.76%. In the near future, autonomous vehicles could be equipped with such a system to perform a fully automatic inspection.","Diogo Gara Caetano, Innovation Director, Kasco R&D Technology",Energy / Oil & Gas
Analytic Spherical Harmonic Gradients for Real-Time Rendering with Many Polygonal Area Lights [P22297],"We develop a novel analytic formula for the spatial gradients of the spherical harmonic coefficients for uniform polygonal area lights. The result is a significant generalization, involving the Reynolds transport theorem to reduce the problem to a boundary integral, for which we derive a new analytic formula, showing how to reduce a key term to an earlier recurrence for SH coefficients. The implementation requires only minor additions to existing code for SH coefficients. The results also hold implications for recent efforts on differentiable rendering. We show that SH gradients enable very sparse spatial sampling, followed by accurate Hermite interpolation. This enables scaling PRT to hundreds of area lights with minimal overhead and real-time frame rates. Moreover, the SH gradient formula is a new mathematical result that potentially enables many other graphics applications.","Lifan Wu, Ph.D. Student, University of California, San Diego",Higher Education / Research
A New Convolution Algorithm to Leverage Tensor Cores [P21960],"The convolution of 2D images is prominent in many data processing pipelines. GPU implementations are already very well optimized in some contexts. For example, the cuDNN library relies on hardware accelerators (tensor cores) to accelerate CNNs. However, the underlying algorithm is only efficient for batched convolutions with small kernels. Many image-processing pipelines do not fit this use case. In our poster, we present a new algorithm leveraging tensor cores in more generic scenarios for 2D convolutions. We focus on the direct use of tensor cores from CUDA and several custom optimizations to get the best of their performance with the help from Nsight-Compute.","Mickaël Seznec, Ph.D. Student, Thales / Centralesupelec",All Industries
An Improved Immersed Boundary-Lattice Boltzmann Method for Incompressible Fluid-Flow Simulations on GPU [P21931],"We introduce the immersed boundary and the lattice Boltzmann method for fluid-solid interaction. The advantage of the lattice Boltzmann method is that it can be easily parallelized. We use a computational study to demonstrate how the immersed body discretization affects the numerical results. We introduce a modification that improves stability, and compare the performance of both methods using several benchmarks problems. These problems show how the immersed body discretization affects the numerical results, mainly the overall drag force and the permeability of the discretized body boundary. Finally, we discuss a performance analysis of different solvers for linear systems.","Pavel Eichler, Ph.D. Student, Faculty of Nuclear Sciences and Physical Engineering, Czech Technical University, Prague",Higher Education / Research
An Intelligent System for In-Field Detection of Invasive Vegetation [P21925],"We show how semantic segmentation with deep learning is suitable for detecting a target plant in aerial imagery when a suitable loss function is used. We use the U-Net architecture and weight-map-based loss, which is suitable because the target plants have indistinct edges. We also demonstrate integrating the model with a drone for in-flight detections. We present samples of the predictions made by the trained model on the test set, as well samples of those made in the field.","Katherine James, M.S. Candidate, Rhodes University",Other
A Performance-Portable Diffusion Solver Based on Axom [P21892],"The sheer size and complexity of large-scale multiphysics codes motivate maintenance of a single-source codebase that is parallel and readily portable across different architectures. This is especially attractive due to recent trends toward heterogeneous architectures. We present Mint, an API that provides a mesh-aware, fine-grain, parallel execution model that underpins the development of computational tools and discretization methods. We build a 2D finite-volume diffusion solver that models separation of chemical species that arise in inertial confinement fusion. We demonstrate portability of the solver across two different architectures, one on a CPU-based architecture and one with CPU+GPU architecture. When compiled with the CUDA backend relative to the OpenMP backend, we find up to 3.5x speedup, demonstrating the viability of the API.","Tyler Masthay, Research Assistant, University of Texas at Austin",National Labs / Research Computing Centers
Applications of Convolutional Neural Network to the Important Earth Science Problems [P22283],"We applied the convolutional neural network to several Earth science problems that involve (1) discrimination of seismic signals from earthquakes and tectonic tremors; (2) determination of an earthquake hypocenter; and (3) solar radiation estimation from fixed-point camera images. Monitoring tremor activity provides insights into deformation processes of megathrust earthquakes. We could achieve 99.5% accuracy for identifications of signals from tremors, regular earthquakes, and noise. We establish neural networks for the determination of hypocentral parameters. We calculate theoretical seismograms for a realistic 3D Earth model and use these seismograms as learning dataset. We can determine an earthquake hypocenter with this neural network. We develop a new observation method that used deep learning to estimate the amount of solar radiation from images. This new technique can be used to make multifaceted observations.","Daisuke Sugiyama, Engineer, Japan Agency for Marine-Earth Science and Technology",National Labs / Research Computing Centers
A Software Systolic Array on GPUs [P22277],"We propose a versatile high-performance execution model, inspired by systolic arrays, for memory-bound regular kernels running on CUDA-enabled GPUs. More specifically, we build a virtual systolic array on the top of CUDA architecture. We formulate a systolic model that shifts partial sums by CUDA warp primitives for the computation. We also employ register files as a cache resource in order to operate the entire model efficiently. We demonstrate the effectiveness and the versatility of the proposed model for a wide variety of stencil kernels that appear commonly in HPC, and also convolution kernels (increasingly important in deep-learning workloads). Our algorithm outperforms the top reported state-of-the-art stencil implementations, including implementations with sophisticated temporal and spatial blocking techniques. For 2D convolution of general filter sizes and shapes, our algorithm is on average 2.5 times faster than NVIDIA’s NPP on Tesla V100 and P100 GPUs.","Mohamed Wahib, Senior Researcher, AIST-Tokyo Tech Real World Big-Data Computation Open Innovation Laboratory, National Institute of Advanced Industrial Science and Technology",Architecture / Engineering / Construction
Automated and Intelligent Cloud Bursting Tool using Deep Neural Networks [P21917],"We'll highlight the need to look at cloud as a suitable option for risk computation in banks and financial institutions, and provide a framework for intelligent, automated, and cost-effective models using hybrid cloud for risk analytics computation. The two variations seen in financial risk computation —periodic but intensive risk computation, such as quarterly stress testing and daily computation that peaks due to ad hoc surge requests, such as what-if analysis — are both very suitable for hybrid cloud-based implementation, given the cost advantages.","Rajesh Kulkarni, Consultant, TATA Consultancy Services",Finance
AWDF: An Adaptive Weighted Deep Fusion Architecture for Multi-Modality Learning [P21985],"Deep model fusion is getting lots of attention in dealing with multi-modality learning problems. We propose an Adaptive Weighted Deep Fusion scheme (AWDF) to capture potential relationships among various input sources. It integrates the feature-level and decision-level fusion in one framework. To address the limitations of existing fusing models with fixed weights, we also propose a new scheme named Cross Decision Weights Method (CDWM). It can dynamically learn the weight for each input branch during the fusion process instead of utilizing predefined weights. To evaluate the performance of AWDF, we conducted experiments on three different real-world datasets: Wild Business Terms, Iceberg Detection, and CareerCon. Our experiments demonstrate that AWDF outperforms other fusion systems by a large margin. (This work has been accepted by IEEE Big Data 2019 Special Session on Intelligent Data Mining).","Qinghan Xue, Applied Data Scientist, IBM",Cloud Services
BasketballGAN : Generating Basketball Play Simulation Through Sketching [P21206],"Given an offensive set play sketch, our method simulates potential scenarios that can occur in the game. The simulation provides coaches and players with insights on how a given set play can be executed. To do this, we train a conditional adversarial network on NBA movement data to imitate the behaviors of how players move around the court. Code and user study are available on GitHub.","Cheng-Kuang Lee, Senior Solution Architect, NVIDIA",Media & Entertainment
Benanza: Automatic μBenchmark Generation to Compute ”Lower-bound” Latency and Inform Optimizations of Deep Learning Models on GPUs [P21858],"Current profiling tools lack the highly desired abilities to characterize ideal performance, identify sources of inefficiency, and quantify the benefits of potential optimizations. Such deficiencies have led to slow characterization/optimization cycles that can't keep up with the fast pace at which new DL models are introduced. We propose Benanza, a sustainable and extensible benchmarking and analysis design that speeds up the characterization/optimization cycle of DL models on GPUs.","Abdul Dakkak, Ph.D. Student, University of Illinois Urbana-Champaign",Higher Education / Research
Beyond-Line-of-Sight (BLOS) Perception System for Autonomous Vehicles [P21842],"Recently, autonomous vehicle perception systems show great performance based on deep-learning technology. Cameras and lidar are commonly used for autonomous driving. However, onboard sensors naturally have limited line-of-sight. Our work introduces a BLOS (beyond-line-of-sight) perception system that mutually complements communicated perception with V2X technology and local perception with onboard sensors. The proposed system is integrated into a full-scale vehicle, and we validated the performance and potential by experiments in the real world.","Chanyoung Chung, Researcher, KAIST (Korea Advanced Institute of Science and Technology)",Automotive / Transportation
Bike-Share Demand Prediction from Partial Future data Using Conditional Variational AutoEncoders [P21739],"Recently, bike-sharing services are working worldwide. One important aspect of bike-share management is to periodically rebalance the positions of the available bikes. Because the bike demand varies by and over time, the number of bikes at each bike-port tends to become unbalanced. To efficiently rebalance a bike-share system, it is essential to predict the number of bikes in each bike-port. In this poster, we propose a method to predict the bike demand at each bike-port every hour, up to 24 hours ahead. This method is based on Variational AutoEncoders and Sequence-to-Sequence Neural Networks. We called this method “Conditional Variational AutoEncoders considering Partial Future data”. In the experiment, our proposal method showed higher prediction accuracy than the other methods.","Mimura Tomohiro, Software Engineer, NTT DOCOMO, INC.",Automotive / Transportation
CapsNet-Lite: A Lightweight and High Performance CapsNet Architecture [P21854],"The capsule network (CapsNet) includes a new type of layer composed by ""capsules"". A capsule is a vector that stores in each position the amount of a certain object feature that's present in the image. Then, those capsules are combined to output the label of the object. To learn how to combine the capsules, this network also needs a routing algorithm. This type of network achieves very high accuracy in classification problems. We propose a modified CapsNet architecture called CapsNet-Lite that outperforms the original proposal in accuracy, with a much faster training procedure.","Francisco José García, Ph.D. Student, Universidad Rey Juan Carlos",Higher Education / Research
Capsule Networks for 3D Pose Estimation in Computer Graphics [P21924],"Pose estimation is an important task for novel engineering applications, such as virtual and augmented reality (VR/AR), pose-based video games, object reconstruction, target tracking, driving assistance, and recent sports analytics. Commonly, an efficient pose estimation system depends on the pose visualization given by a 3D configuration of location, orientation, and scaling parameters of the target. In this work, we implement Capsule Networks to solve 3D pose estimation in computer graphics of rigid objects using a multi-GPU architecture.","Kenia Picos, Professor, CETYS Universidad",Higher Education / Research
cGAN for Automatic Site Selection of Cultural Venues [P22404],"Cultural venues, such as libraries, theaters, cinemas, and galleries, contribute to a city’s tourism and economy and enrich the cultural life of the local residents. In this work, we propose a novel approach to automatic site selection of cultural venues in an urban area, which requires less expertise in urban planning. The two-stage approach consists of a learning stage for predicting zones as a prior constraint, and an optimization stage for determining the number of cultural venues and their exact locations according to multiple criteria. Given an input set of urban data, our approach generates an optimal configuration of two-dimensional locations for cultural venues that complies with land-use policies and provides easy access for the public. We implemented the approach using reliable methods of deep learning and stochastic optimization, and the results demonstrate the approach's effectiveness by a comparison to real-world counterparts.","Tomasz Bednarz, Director of Visualisation, CSIRO and UNSW",Other
CheetahDB: A System for High-Throughput Database Processing on GPUs [P22073],"GPU database is an active topic in academic research and industrial practice. However, existing systems have not shown significant performance advantages over CPU-based in-memory database management systems (DBMS). Two main factors contributed to such difficulties: First, the CUDA programming model, by focusing on HPC-type workloads, requires non-trivial basic research to address the many technical challenges in developing a DBMS system software; and second, I/O bottleneck between host and GPU offsets the performance gain of onboard query processing. CheetahDB is a high-performance in-memory DBMS generated from NSF-supported research at the database group in the University of South Florida and commercialized by Cheetah Data Systems, Inc. CheetahDB addresses the above challenges via a complete rethinking of the software architecture of a DBMS under today’s multi-core hardware environment.","Chengcheng Mou, Student, University of South Florida",Higher Education / Research
Computer Vision in Agriculture: Racing with Pests and Diseases [P22001],"Modern technologies of GPU computing and machine learning allow us to create an autonomous system of greenhouse plant condition control. We combined multiple sensor systems with a photo/video surveillance system, which allows us to create a comprehensive control system helpful for early detection of pests and diseases. We strive to create a stable and reliable solution for AI-based early plant disease detection, disease classification, pest detection, and plant development monitoring. We present our working solutions for vertical farming and a prototype of a more general system.","Ivan Molodtsov, Head of Machine Learning, Fermata",Healthcare & Life Sciences
Container-Based Artificial Intelligence Applications Deployment Platform for GPU High Performance Computing Clusters [P21902],"A container-based AI applications deployment platform was proposed and implemented in our center to solve root privileges and network issues in HPC clusters. A virtual machine is used to simulate the targeted HPC cluster, which has the same or similar runtime environment including compilers, shared libraries, and GPU drivers based on a GPU card attached by PCI pass-through way. Users can have root privileges of virtual machines to set up containers. Further, a user can create containers and deploy AI applications by network tools, because each user has an exclusive virtual machine running on an independent server that connects to internet. The deploy platform and the HPC clusters are connected by a 10Gb/s, or even 100Gb/s network so that users can transfer the container images quickly and easily.","Rongqiang Cao, Associate Professor, Computer Network Information Center, Chinese Academy of Sciences",Cloud Services
Data-Driven Approach of Coronary Vessel Reconstruction Using X-ray Angiography [P21799],"Coronary artery disease is typically diagnosed using X-ray angiography. The percent stenosis, or narrowing of the blood vessel, is estimated via visual inspection of 2D angiography images; however, image artifacts and non-ideal projection angles can lead to miscalculation of disease severity. To address this problem, we propose a data-driven method to reconstruct the 3D geometry of the coronary vessels. A convolutional neural network was trained to segment vessels from angiography images. The segmented binary images were subsequently used as input images for several 3D reconstruction algorithms. The reconstructed 3D geometry can be used as input data for computational fluid dynamics analysis to characterize the hemodynamics of the diseased vessel and thus further improve diagnostic accuracy.","Kritika Iyer, Ph.D. Candidate, University of Michigan",Healthcare & Life Sciences
Data-Efficient Weakly Supervised Histology Classification Using Contrastive Predictive Coding [P22025],"Neural network classification models can be trained on weakly annotated medical imaging data using multiple instance learning (MIL). However, due to weak supervisory signals, direct application of MIL suffers from overfitting when faced with limited labeled data and the network is unable to learn rich feature representations. To overcome such limitations, we propose a two-stage semi-supervised approach that combines data-efficient self-supervised feature learning via contrastive predictive coding (CPC) and attention-based MIL. Across five random splits, we report state-of-the-art performance with a mean validation accuracy of 95% and an area under the ROC curve of 0.968 on a breast cancer classification dataset. We evaluate the quality of features learned via CPC relative to simple transfer learning and show that strong classification performance using CPC features can be efficiently leveraged under the MIL framework using limited labels and with the feature encoder frozen.","Ming Yang Lu, Research Intern , Computational Pathology, Brigham and Women's Hospital, Harvard Medical School",Healthcare & Life Sciences
Data Mining Pipeline for Predictive Synthesis of Advanced Materials [P22007],"Materials discovery is significantly facilitated and accelerated by high-throughput ab-initio computations. Being able to rapidly design advanced compounds has displaced the materials-innovation bottleneck to developing synthesis routes for the desired material. As there isn't a fundamental theory for materials synthesis, one might attempt a data-driven approach for predicting inorganic materials synthesis, but this is impeded by the lack of a comprehensive database of synthesis parameters. We've generated a dataset of “codified recipes” for solid-state synthesis automatically extracted from scientific publications. The dataset consists of about 20,000 synthesis entries retrieved from over 50,000 solid-state synthesis paragraphs by using text mining and natural language processing approaches. The dataset is publicly available and can be used for data mining of various aspects of inorganic materials synthesis.","Olga Kononova, Postdoctoral Scholar, University of California, Berkeley",Higher Education / Research
Decoding Texture Information from Rat Somatosensory Cortical Neurons Using CNN [P21855],"Neurons in the neocortex often exhibit feature selectivity against external stimuli. Simple stimuli can be decoded from activity of a single neuron; however, it has been poorly understood whether more complicated features can be decoded from the neuronal activity. To address this question, we recorded local field potentials (LFPs), which reflect the activity of thousands of neurons, of rats given complex sensory stimuli and took advantage of a convolutional neural network (CNN) for decoding. To this end, we developed a novel electrode array that enables wide-range recording from the superficial layers of the cortex. We recorded LFPs from the primary somatosensory cortex (S1) of a rat exploring on either rough or smooth floor. Our CNN model yielded 78% accuracy on average for decoding the surface texture. This suggests that somatosensory LFPs contain enough information to decode a surface texture.","Kotaro Yamashiro, Ph.D. Student, The University Tokyo, Graduate School of Pharmaceutical Sciences",Higher Education / Research
Deep Autoencoder-Based Statistical Arbitrage During a Bearish Market [P22088],"During a market that is headed generally downward, an investor can use long and short positions at key points in time for profit. We introduce a deep autoencoder as a type of neural network to observe the return patterns for a basket of Dow 30 stocks, using a GPU to accelerate this unsupervised learning process. Depending upon the strength of the GPU, we can observe more rapid training, which helps our back-testing and hyper-parameter search process and has an impact on profitability.","Mark Bennett, Senior Solutions Architect, NVIDIA",Finance
"Deep Learning-Aided Label-Free, Real-Time and Time-Lapse “Cell Visualization” Technology that Enables Live/Dead Cell Discrimination and Counting [P21952]","""Cell visualization"" is a new technology that can predict cell properties, such as cell life and death, from bright-field cell images. It's necessary to build a deep-learning model in which the relationship between a teacher cell image, such as fluorescence labeling indicating cell properties, and the corresponding bright-field cell image is finely learned. Inputting unknown bright-field cell images to the constructed learning model generates a pseudo-fluorescent labeling image showing the characteristics of the cells, enabling ""visualization of cells."" The present technology may replace many cell assays in drug discovery by solving the invasiveness of fluorescence-based cell assays. This technology also realizes real-time monitoring of cell quality. This innovative cell digitization technology is expected to become essential in the fields of drug discovery and regenerative medicine.","Tamio Mizukami, Professor, Nagahama Institute of Bio-Science and Technology",Healthcare & Life Sciences
Deep Learning-Based Anti-Drone System [P21900],This poster is about research on detecting and tracking drones by applying deep learning technology to capture drones that are illegally operated.,"Hanseob Lee, Ph.D. Candidate, KAIST",Aerospace / Defense / Government
Deep-Learning Model for Finding New Superconductors [P21328],"We report the first deep-learning model for finding new superconductors. We represented the periodic table in such a way that deep learning can learn it. Although we used only the chemical composition of materials as information, we obtained an R2 value of 0.92 for predicting Tc for materials in a database of superconductors. We obtained three remarkable results. The deep-learning method can predict superconductivity for a material with a precision of 62\%, which shows the usefulness of the model; it found the recently discovered superconductor CaBi2, which is not in the superconductor database; and it found Fe-based high-temperature superconductors (discovered in 2008) from the training data before 2008. These results open the way for the discovery of new high-temperature superconductor families.","Tomohiko Konno, Researcher, National Institute of Information and Communications Technology",Aerospace / Defense / Government
D-GEN: A Deep Learning Data Generation Framework for Artificial Intelligence [P22097],"Synthetic data is an increasingly popular and powerful tool for training deep-learning models, especially in computer vision tasks as well as other areas. In this work, we present a synthetic training data-generation framework for artificial intelligence. This work includes a variety of technology fields: GPU-based big data computing, game engine-based image generation, probabilistic generative models (GANs, VAE), domain randomization, and automatic data augmentation. GPU-based 3D rendering and deep neural nets training accelerate the wide use of generated massive synthetic dataset for artificial intelligence. Synthetic data works well on a variety of military tasks and domains. We believe that synthetic data is essential for deep learning-based machine intelligence in data-scarce fields.","Se-Yoon Oh, Big Data Team Leader, Agency for Defense Development",All Industries
Distributed Deep Learning for Automatic Disease Detection Systems [P22078],"Deep neural networks and other deep-learning approaches are providing diagnostic capabilities on a par with medical specialists. If deployed in the field, these DL applications and devices can help to detect health conditions early and develop preventive approaches. However, deploying such systems requires large compute infrastructure. To address the infrastructure issues, I developed a distributed cost-effective approach using edge devices and a cloud-based central hub for better predictions. To test its effectiveness, I applied it to diagnosing eye conditions using fundus images.","Ananya Gangavarapu, Student, Princeton International School of Mathematics and Science",Healthcare & Life Sciences
Dramatic Acceleration of Quantum Transport Simulations: Solving Non-Equilibrium Green’s Function with GPU Devices [P21787],"The poster presents in-depth discussion on technical details and strategies for GPU-driven performance enhancement in solving the Non-Equilibrium Green's Function (NEGF), which is critically used to simulate quantum transport behaviors of electronic devices in a nanoscale regime. Although here we focus on NEGF as a main target of performance enhancement, the contents (particularly the strategies of performance improvement with GPU computing) presented in this poster can be still useful for ANY numerical problems that involve the computation of an inverse of block-tridiagonal (dense/sparse, real/complex) matrices.","Yosang Jeong, Researcher, Korea Institute of Science and Technology Information",National Labs / Research Computing Centers
Drones as a Tool for Development and Safety Validation of Automated Driving Functions [P21913],"Automated driving heavily relies on data-driven methods. Large datasets of real-world measurement data, in the form of road-user trajectories, are crucial for several tasks, such as road-user prediction models or scenario-based safety validation. Using a drone has the major advantage of recording naturalistic behavior. Due to the ideal viewing angle, an entire scenario can be measured with significantly less occlusion than with sensors at ground level. Both the class and the trajectory of each road user can be extracted from the video recordings with high precision using state-of-the-art deep neural networks. Therefore, we have created a large-scale urban intersection dataset with naturalistic road-user behavior using camera-equipped drones. The resulting dataset contains road users including vehicles, bicyclists, and pedestrians at intersections in Germany, and is called inD. The dataset is available online for non-commercial research at: http://www.inD-dataset.com.","Julian Bock, Manager Artificial Intelligence, fka GmbH",Automotive / Transportation
